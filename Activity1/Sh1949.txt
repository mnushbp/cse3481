Communication Theory of Secrecy Systems? 
By C. E. SHANNON 
   INTRODUCTION AND SUMMARY 
The problems of cryptography and secrecy systems furnish an interesting ap-plication of communication theory1. In this paper a theory of secrecy systems is developed. The approach is on a theoretical level and is intended to com-plement the treatment found in standard works on cryptography2. There, a detailed study is made of the many standard types of codes and ciphers, and of the ways of breaking them. We will be more concerned with the general mathematical structure and properties of secrecy systems. 
   The treatment is limited in certain ways. First, there are three general types of secrecy system: (1) concealment systems, including such methods as invisible ink, concealing a message in an innocent text, or in a fake cov-ering cryptogram, or other methods in which the existence of the message is concealed from the enemy; (2) privacy systems, for example speech in-version, in which special equipment is required to recover the message; (3) “true” secrecy systems where the meaning of the message is concealed by cipher, code, etc., although its existence is not hidden, and the enemy is as-sumed to have any special equipment necessary to intercept and record the transmitted signal. We consider only the third type—concealment system are primarily a psychological problem, and privacy systems a technological one. 
   Secondly, the treatment is limited to the case of discrete information where the message to be enciphered consists of a sequence of discrete sym-bols, each chosen from a ?nite set. These symbols may be letters in a lan-guage, words of a language, amplitude levels of a “quantized” speech or video signal, etc., but the main emphasis and thinking has been concerned with the case of letters. 
   The paper is divided into three parts. The main results will now be brie?y summarized. The ?rst part deals with the basic mathematical structure of secrecy systems. As in communication theory a language is considered to be represented by a stochastic process which produces a discrete sequence of 
? The material in this paper appeared in a con?dential report “A Mathematical Theory of Cryptogra-phy” dated Sept.1, 1946, which has now been declassi?ed. 1 Shannon, C. E., “A Mathematical Theory of Communication,” Bell System Technical Journal, July 1948, p.623. 
2 See, for example, H. F. Gaines, “Elementary Cryptanalysis,” or M. Givierge, “Cours de Cryptogra-phie.” 
symbols in accordance with some system of probabilities. Associated with a language there is a certain parameter D which we call the redundancy of the language. D measures, in a sense, how much a text in the language can be reduced in length without losing any information. As a simple example, since ualways follows qin English words, the umay be omitted without loss. Considerable reductions are possible in English due to the statistical structure of the language, the high frequencies of certain letters or words, etc. Redundancy is of central importance in the study of secrecy systems. 
   A secrecy system is de?ned abstractly as a set of transformations of one space (the set of possible messages) into a second space (the set of possible cryptograms). Each particular transformation of the set corresponds to enci-phering with a particular key. The transformations are supposed reversible (non-singular) so that unique deciphering is possible when the key is known. 
   Each key and therefore each transformation is assumed to have an a priori probability associated with it—the probability of choosing that key. Similarly each possible message is assumed to have an associated a priori probability, determined by the underlying stochastic process. These probabilities for the various keys and messages are actually the enemy cryptanalyst’s a priori probabilities for the choices in question, and represent his a priori knowledge of the situation. 
   To use the system a key is ?rst selected and sent to the receiving point. The choice of a key determines a particular transformation in the set form-ing the system. Then a message is selected and the particular transformation corresponding to the selected key applied to this message to produce a cryp-togram. This cryptogram is transmitted to the receiving point by a channel and may be intercepted by the “enemy?.” At the receiving end the inverse of the particular transformation is applied to the cryptogram to recover the original message. 
   If the enemy intercepts the cryptogram he can calculate from it the a pos-teriori probabilities of the various possible messages and keys which might have produced this cryptogram. This set of a posteriori probabilities consti-tutes his knowledge of the key and message after the interception. “Knowl-edge” is thus identi?ed with a set of propositions having associated proba-bilities. The calculation of the a posteriori probabilities is the generalized problem of cryptanalysis. 
   As an example of these notions, in a simple substitution cipher with ran-dom key there are 26!transformations, corresponding to the 26!ways we can substitute for 26different letters. These are all equally likely and each there-
1
fore has an a priori probability 26! 
. If this is applied to “normal English” 
? The word “enemy,” stemming from military applications, is commonly used in cryptographic work to denote anyone who may intercept a cryptogram. 
the cryptanalyst being assumed to have no knowledge of the message source other than that it is producing English text, the a priori probabilities of var-ious messages of Nletters are merely their relative frequencies in normal English text. 
   If the enemy intercepts Nletters of cryptograms in this system his prob-abilities change. If Nis large enough (say 50letters) there is usually a single message of a posteriori probability nearly unity, while all others have a total probability nearly zero. Thus there is an essentially unique “solution” to the cryptogram. For Nsmaller (say N=15) there will usually be many mes-sages and keys of comparable probability, with no single one nearly unity. In this case there are multiple “solutions” to the cryptogram. 
   Considering a secrecy system to be represented in this way, as a set of transformations of one set of elements into another, there are two natural combining operations which produce a third system from two given systems. The ?rst combining operation is called the product operation and corresponds to enciphering the message with the ?rst secrecy system Rand enciphering the resulting cryptogram with the second system S, the keys for Rand Sbeing chosen independently. This total operation is a secrecy system whose transformations consist of all the products (in the usual sense of products of transformations) of transformations in Swith transformations in R. The probabilities are the products of the probabilities for the two transformations. 
   The second combining operation is “weighted addition.” 
T = pR + qS p + q =1 
It corresponds to making a preliminary choice as to whether system Ror Sis to be used with probabilities pand q, respectively. When this is done Ror Sis used as originally de?ned. 
   It is shown that secrecy systems with these two combining operations form essentially a “linear associative algebra” with a unit element, an alge-braic variety that has been extensively studied by mathematicians. 
   Among the many possible secrecy systems there is one type with many special properties. This type we call a “pure” system. A system is pure if all keys are equally likely and if for any three transformations Ti,Tj,Tkin the set the product 
TiTj ?1Tk 
is also a transformation in the set. That is, enciphering, deciphering, and en-ciphering with any three keys must be equivalent to enciphering with some key. 
   With a pure cipher it is shown that all keys are essentially equivalent— they all lead to the same set of a posteriori probabilities. Furthermore, when a given cryptogram is intercepted there is a set of messages that might have produced this cryptogram (a “residue class”) and the a posteriori probabili-ties of message in this class are proportional to the a priori probabilities. All the information the enemy has obtained by intercepting the cryptogram is a speci?cation of the residue class. Many of the common ciphers are pure sys-tems, including simple substitution with random key. In this case the residue class consists of all messages with the same pattern of letter repetitions as the intercepted cryptogram. 
   Two systems Rand Sare de?ned to be “similar” if there exists a ?xed transformation Awith an inverse, A?1, such that 
R = AS. 
If Rand Sare similar, a one-to-one correspondence between the resulting cryptograms can be set up leading to the same a posteriori probabilities. The two systems are cryptanalytically the same. 
   The second part of the paper deals with the problem of “theoretical se-crecy”. How secure is a system against cryptanalysis when the enemy has unlimited time and manpower available for the analysis of intercepted cryp-tograms? The problem is closely related to questions of communication in the presence of noise, and the concepts of entropy and equivocation devel-oped for the communication problem ?nd a direct application in this part of cryptography. 
   “Perfect Secrecy” is de?ned by requiring of a system that after a cryp-togram is intercepted by the enemy the a posteriori probabilities of this cryp-togram representing various messages be identically the same as the a pri-ori probabilities of the same messages before the interception. It is shown that perfect secrecy is possible but requires, if the number of messages is ?-nite, the same number of possible keys. If the message is thought of as being constantly generated at a given “rate” R(to be de?ned later), key must be generated at the same or a greater rate. 
   If a secrecy system with a ?nite key is used, and Nletters of cryptogram intercepted, there will be, for the enemy, a certain set of messages with cer-tain probabilities that this cryptogram could represent. As Nincreases the ?eld usually narrows down until eventually there is a unique “solution” to the cryptogram; one message with probability essentially unity while all oth-ers are practically zero. A quantity H(N)is de?ned, called the equivocation, which measures in a statistical way how near the average cryptogram of Nletters is to a unique solution; that is, how uncertain the enemy is of the orig-inal message after intercepting a cryptogram of Nletters. Various properties of the equivocation are deduced—for example, the equivocation of the key never increases with increasing N. This equivocation is a theoretical secrecy index—theoretical in that it allows the enemy unlimited time to analyse the cryptogram. 
   The function H(N)for a certain idealized type of cipher called the ran-dom cipher is determined. With certain modi?cations this function can be applied to many cases of practical interest. This gives a way of calculating approximately how much intercepted material is required to obtain a solution to a secrecy system. It appears from this analysis that with ordinary languages and the usual types of ciphers (not codes) this “unicity distance” is approxi-mately H(K). Here H(K)is a number measuring the “size” of the key space. 
D 
If all keys are a priori equally likely H(K)is the logarithm of the number of possible keys. Dis the redundancy of the language and measures the amount of “statistical constraint” imposed by the language. In simple substitution with random key H(K)is log1026!or about 20and D(in decimal digits per letter) is about .7for English. Thus unicity occurs at about 30 letters. 
   It is possible to construct secrecy systems with a ?nite key for certain “languages” in which the equivocation does not approach zero as N??. In this case, no matter how much material is intercepted, the enemy still does not obtain a unique solution to the cipher but is left with many alternatives, all of reasonable probability. Such systems we call ideal systems. It is possible in any language to approximate such behavior—i.e., to make the approach to zero of H(N)recede out to arbitrarily large N. However, such systems have a number of drawbacks, such as complexity and sensitivity to errors in transmission of the cryptogram. 
   The third part of the paper is concerned with “practical secrecy”. Two systems with the same key size may both be uniquely solvable when Nletters have been intercepted, but differ greatly in the amount of labor required to effect this solution. An analysis of the basic weaknesses of secrecy systems is made. This leads to methods for constructing systems which will require a large amount of work to solve. Finally, a certain incompatibility among the various desirable qualities of secrecy systems is discussed. 
                       PART I MATHEMATICAL STRUCTURE OF SECRECY SYSTEMS 
   SECRECY SYSTEMS 
As a ?rst step in the mathematical analysis of cryptography, it is necessary to idealize the situation suitably, and to de?ne in a mathematically acceptable way what we shall mean by a secrecy system. A “schematic” diagram of a general secrecy system is shown in Fig. 1. At the transmitting end there are two information sources—a message source and a key source. The key source produces a particular key from among those which are possible in the system. This key is transmitted by some means, supposedly not interceptible, for ex-ample by messenger, to the receiving end. The message source produces a message (the “clear”) which is enciphered and the resulting cryptogram sent to the receiving end by a possibly interceptible means, for example radio. At the receiving end the cryptogram and key are combined in the decipherer to recover the message. 
     ENEMY CRYPTANALYST 
E 
MESSAGE SOURCE MESSAGE 
CRYPTOGRAM 
 MESSAGE 
M 
E 
M 

KEY K 
SOURCE 
Fig. 1. Schematic of a general secrecy system 
   Evidently the encipherer performs a functional operation. If Mis the mes-sage, Kthe key, and Ethe enciphered message, or cryptogram, we have 
                         E=f(M,K)that is Eis function of Mand K. It is preferable to think of this, however, not as a function of two variables but as a (one parameter) family of operations or transformations, and to write it 
                          E=TiM.The transformation Tiapplied to message Mproduces cryptogram E. The index icorresponds to the particular key being used. We will assume, in general, that there are only a ?nite number of possible keys, and that each has an associated probability pi. Thus the key source is represented by a statistical process or device which chooses one from the set of transformations T1,T2,···,Tmwith the respective probabilities p1,p2,···,pm. Similarly we will generally assume a ?nite number of possible messages M1,M2,···,Mnwith associate a priori probabilities q1,q2,···,qn. The possible messages, for example, might be the possible sequences of En-glish letters all of length N, and the associated probabilities are then the relative frequencies of occurrence of these sequences in normal English text. 
At the receiving end it must be possible to recover M, knowing Eand 
K. Thus the transformations Tiin the family must have unique inverses Ti ?1 such that TiTi ?1 =I, the identity transformation. Thus: 
M = Ti ?1E. 
At any rate this inverse must exist uniquely for every Ewhich can be ob-tained from an Mwith key i. Hence we arrive at the de?nition: A secrecy system is a family of uniquely reversible transformations Ti of a set of possible messages into a set of cryptograms, the transformation Ti having an associated probability pi. Conversely any set of entities of this type will be called a “secrecy system”. The set of possible messages will be called, for convenience, the “message space” and the set of possible cryptograms the “cryptogram space”. 
   Two secrecy systems will be the same if they consist of the same set of transformations Ti, with the same messages and cryptogram space (range and domain) and the same probabilities for the keys. 
   A secrecy system can be visualized mechanically as a machine with one or more controls on it. A sequence of letters, the message, is fed into the in-put of the machine and a second series emerges at the output. The particular setting of the controls corresponds to the particular key being used. Some sta-tistical method must be prescribed for choosing the key from all the possible ones. 
   To make the problem mathematically tractable we shall assume that the enemy knows the system being used. That is, he knows the family of trans-formations Ti, and the probabilities of choosing various keys. It might be ob-jected that this assumption is unrealistic, in that the cryptanalyst often does not know what system was used or the probabilities in question. There are two answers to this objection: 
1 The restriction is much weaker than appears at ?rst, due to our broad de?nition of what constitutes a secrecy system. Suppose a cryptographer intercepts a message and does not know whether a substitution transposi-tion, or Vigen`ere type cipher was used. He can consider the message as being enciphered by a system in which part of the key is the speci?cation of which of these types was used, the next part being the particular key for that type. These three different possibilities are assigned probabilities ac-cording to his best estimates of the a priori probabilities of the encipherer using the respective types of cipher. 
2 The assumption is actually the one ordinary used in cryptographic studies. It is pessimistic and hence safe, but in the long run realistic, since one must expect his system to be found out eventually. Thus, even when an entirely new system is devised, so that the enemy cannot assign any a 

priori probability to it without discovering it himself, one must still live with the expectation of his eventual knowledge. 
The situation is similar to that occurring in the theory of games3 where it is assumed that the opponent “?nds out” the strategy of play being used. In both cases the assumption serves to delineate sharply the opponent’s knowledge. 
   A second possible objection to our de?nition of secrecy systems is that no account is taken of the common practice of inserting nulls in a message and the use of multiple substitutes. In such cases there is not a unique cryp-togram for a given message and key, but the encipherer can choose at will from among a number of different cryptograms. This situation could be han-dled, but would only add complexity at the present stage, without substan-tially altering any of the basic results. 
   If the messages are produced by a Markoff process of the type described in (1) to represent an information source, the probabilities of various mes-sages are determined by the structure of the Markoff process. For the present, however, we wish to take a more general view of the situation and regard the messages as merely an abstract set of entities with associated probabil-ities, not necessarily composed of a sequence of letters and not necessarily produced by a Markoff process. 
   It should be emphasized that throughout the paper a secrecy system means not one, but a set of many transformations. After the key is chosen only one of these transformations is used and one might be led from this to de?ne a secrecy system as a single transformation on a language. The enemy, how-ever, does not know what key was chosen and the “might have been” keys are as important for him as the actual one. Indeed it is only the existence of these other possibilities that gives the system any secrecy. Since the secrecy is our primary interest, we are forced to the rather elaborate concept of a se-crecy system de?ned above. This type of situation, where possibilities are as important as actualities, occurs frequently in games of strategy. The course of a chess game is largely controlled by threats which are not carried out. Somewhat similar is the “virtual existence” of unrealized imputations in the theory of games. 
   It may be noted that a single operation on a language forms a degener-ate type of secrecy system under our de?nition—a system with only one key of unit probability. Such a system has no secrecy—the cryptanalyst ?nds the message by applying the inverse of this transformation, the only one in the system, to the intercepted cryptogram. The decipherer and cryptanalyst in this case possess the same information. In general, the only difference be-tween the decipherer’s knowledge and the enemy cryptanalyst’s knowledge 
   3 See von Neumann and Morgenstern “The Theory of Games”, Princeton 1947. 
is that the decipherer knows the particular key being used, while the crypt-analyst knows only the a priori probabilities of the various keys in the set. The process of deciphering is that of applying the inverse of the particular transformation used in enciphering to the cryptogram. The process of crypt-analysis is that of attempting to determine the message (or the particular key) given only the cryptogram and the a priori probabilities of various keys and messages. 
   There are a number of dif?cult epistemological questions connected with the theory of secrecy, or in fact with any theory which involves questions of probability (particularly a priori probabilities, Bayes’ theorem, etc.) when applied to a physical situation. Treated abstractly, probability theory can be put on a rigorous logical basis with the modern measure theory approach45 . As applied to a physical situation, however, especially when “subjective” probabilities and unrepeatable experiments are concerned, there are many questions of logical validity. For example, in the approach to secrecy made here, a priori probabilities of various keys and messages are assumed known by the enemy cryptographer—how can one determine operationally if his es-timates are correct, on the basis of his knowledge of the situation? 
   One can construct arti?cial cryptographic situations of the “urn and die” type in which the a priori probabilities have a de?nite unambiguous meaning and the idealization used here is certainly appropriate. In other situations that one can imagine, for example an intercepted communication between Mar-tian invaders, the a priori probabilities would probably be so uncertain as to be devoid of signi?cance. Most practical cryptographic situations lie some-where between these limits. A cryptanalyst might be willing to classify the possible messages into the categories “reasonable”, “possible but unlikely” and “unreasonable”, but feel that ?ner subdivision was meaningless. 
   Fortunately, in practical situations, only extreme errors in a priori proba-bilities of keys and messages cause signi?cant errors in the important param-eters. This is because of the exponential behavior of the number of messages and cryptograms, and the logarithmic measures employed. 
   REPRESENTATION OF SYSTEMS 
A secrecy system as de?ned above can be represented in various ways. One which is convenient for illustrative purposes is a line diagram, as in Figs. 2 and 4. The possible messages are represented by points at the left and the possible cryptograms by points at the right. If a certain key, say key 1, trans-forms message M2into cryptogram E4then M2and E4are connected by a 
   4 See J. L. Doob, “Probability as Measure”, Annals of Math. Stat., v. 12, 1941, pp. 206–214. 
5 A. Kolmogoroff, “Grundbegriffe der Wahrscheinlichkeitsrechnung”, Ergebnisse der Mathematic, v. 
2, No. 3 (Berlin 1933). 
line labeled 1, etc. From each possible message there must be exactly one line emerging for each different key. If the same is true for each cryptogram, we will say that the system is closed. 
   A more common way of describing a system is by stating the operation one performs on the message for an arbitrary key to obtain the cryptogram. Similarly, one de?nes implicitly the probabilities for various keys by describ-ing how a key is chosen or what we know of the enemy’s habits of key choice. The probabilities for messages are implicitly determined by stating our a pri-ori knowledge of the enemy’s language habits, the tactical situation (which will in?uence the probable content of the message) and any special informa-tion we may have regarding the cryptogram. 
M1 
E1 M2 M1 E2
M3 
M2 E3M4 
CLOSED SYSTEM NOT CLOSED 
Fig. 2. Line drawings for simple systems 
4 SOME EXAMPLES OF SECRECY SYSTEMS 
In this section a number of examples of ciphers will be given. These will often be referred to in the remainder of the paper for illustrative purposes. 
4.1 Simple Substitution Cipher 
In this cipher each letter of the message is replaced by a ?xed substitute, usually also a letter. Thus the message, 
M=m1m2m3m4···
where m1,m2,···are the successive letters becomes: 
E=e1e2e3e4···=f(m1)f(m2)f(m3)f(m4)···
where the function f(m)is a function with an inverse. The key is a permuta-tion of the alphabet (when the substitutes are letters) e.g. XGUACDTBFHRSLMQVYZWIEJOKNP. The ?rst letter Xis the substitute for A, Gis the substitute for B, etc. 
4.2 Transposition (Fixed Period d) 
The message is divided into groups of length dand a permutation applied to the ?rst group, the same permutation to the second group, etc. The permuta-tion is the key and can be represented by a permutation of the ?rst dintegers. Thus for d=5, we might have 23154as the permutation. This means that: 
m1m2m3m4m5m6m7m8m9m10···
becomes 
m2m3m1m5m4m7m8m6m10m9···.
Sequential application of two or more transpositions will be called compound transposition. If the periods are d1,d2,···,dnit is clear that the re-sult is a transposition of period d, where dis the least common multiple of d1,d2,···,dn. 
4.3 Vigen`ere, and Variations 
In the Vigen`ere cipher the key consists of a series of dletters. These are writ-ten repeatedly below the message and the two added modulo 26(considering the alphabet numbered from A=0to Z=25. Thus 
ei=mi+ki(mod 26)
where kiis of period din the index i. For example, with the key GAH, we 
obtain message repeated key cryptogram N O W I S T H E G A H G A H G A T O D O S A N E 
The Vigen`ere of period 1is called the Caesar cipher. It is a simple substitution in which each letter of Mis advanced a ?xed amount in the alphabet. This amount is the key, which may be any number from 0to 25. The so-called Beaufort and Variant Beaufort are similar to the Vigen`ere, and encipher by the equations 
ei=ki?mi(mod 26)
ei=mi?ki(mod 26)
respectively. The Beaufort of period one is called the reversed Caesar cipher. 
   The application of two or more Vigen`ere in sequence will be called the compound Vigen`ere. It has the equation 
ei=mi+ki+li+···+si(mod 26)
666 
where ki,li,···,siin general have different periods. The period of their sum, 
ki + li + ··· + si 
as in compound transposition, is the least common multiple of the individual periods. When the Vigen`ere is used with an unlimited key, never repeating, we have the Vernam system6, with 
                     ei=mi+ki(mod 26)the kibeing chosen at random and independently among 0,1,···,25. If the key is a meaningful text we have the “running key” cipher. 
4.4 Digram, Trigram, and N-gram substitution 
Rather than substitute for letters one can substitute for digrams, trigrams, etc. General digram substitution requires a key consisting of a permutation of the 262 digrams. It can be represented by a table in which the row corresponds to the ?rst letter of the digram and the column to the second letter, entries in the table being the substitutions (usually also digrams). 
4.5 Single Mixed Alphabet Vigen`ere 
This is a simple substitution followed by a Vigen`ere. ei=f(mi)+kimi=f?1(ei?ki)The “inverse” of this system is a Vigen`ere followed by simple substitution 
ei=g(mi+ki)mi=g?1(ei)?ki
4.6 Matrix System 
One method of n-gram substitution is to operate on successive n-grams with a matrix having an inverse7. The letters are assumed numbered from 0to 25, making them elements of an algebraic ring. From the n-gram m 1 m2 ··· mn of message, the matrix aijgives an n-gram of cryptogram 
n 
ei=aijmji=1,···,nj=1
6 G. S. Vernam, “Cipher Printing Telegraph Systems for Secret Wire and Radio Telegraphic Commu-nications”, Journal American Institute of Electrical Engineers, v. XLV, pp. 109–115, 1926. 7 See L. S. Hill, “Cryptography in an Algebraic Alphabet”, American Math. Monthly, v. 36, No. 6, 1, 1929, pp. 306–312; also “Concerning Certain Linear Transformation Apparatus of Cryptography”, 
v. 38, No. 3, 1931, pp. 135–154. 
   The matrix aijis the key, and deciphering is performed with the inverse matrix. The inverse matrix will exist if and only if the determinant |aij|has an inverse element in the ring. 
4.7 The Playfair Cipher 
This is a particular type of digram substitution governed by a mixed 25letter alphabet written in a 5×5square. (The letter Jis often dropped in crypto-graphic work—it is very infrequent, and when it occurs can be replaced by I.) Suppose the key square is as shown below: 
LZQCPAGNOURDMIFKYHVSXBTEW
The substitute for a digram AC, for example, is the pair of letters at the other corners of the rectangle de?ned by Aand C, i.e., LO, the Ltaken ?rst since it is above A. If the digram letters are on a horizontal line as RI, one uses the letters to their right DF; RFbecomes DR. If the letters are on a vertical line, the letters below them are used. Thus PSbecomes UW. If the letters are the same nulls may be used to separate them or one may be omitted, etc. 
4.8 Multiple Mixed Alphabet Substitution 
In this cipher there are a set of lsimple substitutions which are used in se-quence. If the period dis four 
m1 m2 m3 m4 m5 m6 ··· 
becomes 
f1(m1)f2(m2)f3(m3)f4(m4)f1(m5)f2(m6)···
4.9 Autokey Cipher 
A Vigen`ere type system in which either the message itself or the resulting cryptogram is used for the “key” is called an autokey cipher. The encipher-ment is started with a “priming key” (which is the entire key in our sense) and continued with the message or cryptogram displaced by the length of the priming key as indicated below, where the priming key is COMET. The message used as “key”: 
Message SENDSUPPLIES···Key COMETSENDSUP···
Cryptogram USZHLMTCOAYH···
The cryptogram used as “key”8: 
Message SENDSUPPLIES···Key COMETUSZHLOH···
Cryptogram USZHLOHOSTSZ···
4.10 Fractional Ciphers 
In these, each letter is ?rst enciphered into two or more letters or numbers and these symbols are somehow mixed (e.g., by transposition). The result may then be retranslated into the original alphabet. Thus, using a mixed 25-letter alphabet for the key, we may translate letters into two-digit quinary 
numbers by the table: 0 1 2 3 4 0 L Z Q C P 1 A G N O U 2 R D M I F 3 K Y H V S 4 X B T E W 
Thus Bbecomes 41. After the resulting series of numbers is transposed in some way they are taken in pairs and translated back into letters. 
4.11 Codes 
In codes words (or sometimes syllables) are replaced by substitute letter groups. Sometimes a cipher of one kind or another is applied to the result. 
5 VALUATIONS OF SECRECY SYSTEM 
There are a number of different criteria that should be applied in estimating the value of a proposed secrecy system. The most important of these are: 
5.1 Amount of Secrecy 
There are some systems that are perfect—the enemy is no better off after intercepting any amount of material than before. Other systems, although giving him some information, do not yield a unique “solution” to intercepted cryptograms. Among the uniquely solvable systems, there are wide variations in the amount of labor required to effect this solution and in the amount of material that must be intercepted to make the solution unique. 
8 This system is trivial from the secrecy standpoint since, with the exception of the ?rst dletters, the enemy is in possession of the entire “key”. 
669 
5.2 Size of Key 
The key must be transmitted by non-interceptible means from transmitting to receiving points. Sometimes it must be memorized. It is therefore desirable to have the key as small as possible. 
5.3 Complexity of Enciphering and Deciphering Operations 
Enciphering and deciphering should, of course, be as simple as possible. If they are done manually, complexity leads to loss of time, errors, etc. If done mechanically, complexity leads to large expensive machines. 
5.4 Propagation of Errors 
In certain types of ciphers an error of one letter in enciphering or transmission leads to a large number of errors in the deciphered text. The error are spread out by the deciphering operation, causing the loss of much information and frequent need for repetition of the cryptogram. It is naturally desirable to minimize this error expansion. 
5.5 Expansion of Message 
In some types of secrecy systems the size of the message is increased by the enciphering process. This undesirable effect may be seen in systems where one attempts to swamp out message statistics by the addition of many nulls, or where multiple substitutes are used. It also occurs in many “concealment” types of systems (which are not usually secrecy systems in the sense of our de?nition). 
6 THE ALGEBRA OF SECRECY SYSTEMS 
If we have two secrecy systems Tand Rwe can often combine them in various ways to form a new secrecy system S. If Tand Rhave the same domain (message space) we may form a kind of “weighted sum”, 
S = pT + qR 
where p+q=1. This operation consists of ?rst making a preliminary choice with probabilities pand qdetermining which of Tand Ris used. This choice is part of the key of S. After this is determined Tor Ris used as originally de?ned. The total key of Smust specify which of Tand Ris used and which key of T(or R) is used. 
   If Tconsists of the transformations T1,···,Tmwithprobabilities p1,···,pmand Rconsists of R1,···,Rkwith probabilities q1,···,qkthen S=pT+qRconsists of the transformations T1,···,Tm,R1,···,Rkwith probabilities pp1,pp2,···,ppm,qq1,qq2,···,qqkrespectively. 
More generally we can form the sum of a number of systems. 
            S=p1T+p2R+···+pmUpi=1We note that any system Tcan be written as a sum of ?xed operations T=p1T1+p2T2+···+pmTmTibeing a de?nite enciphering operation of Tcorresponding to key choice i, which has probability pi. 

Fig. 3. Product of two systems S = RT 
   A second way of combining two secrecy systems is by taking the “prod-uct”, shown schematically in Fig. 3. Suppose Tand Rare two systems and the domain (language space) of Rcan be identi?ed with the range (cryp-togram space) of T. Then we can apply ?rst Tto our language and then Rto the result of this enciphering process. This gives a resultant operation Swhich we write as a product 
                           S=RTThe key for Sconsists of both keys of Tand Rwhich are assumed chosen according to their original probabilities and independently. Thus, if the mkeys of Tare chosen with probabilities p1p2···pmand the nkeys of Rhave probabilities 
p1 p2 ··· pn, 
then Shas at most mnkeys with probabilities pipj? . In many cases some of the product transformations RiTjwill be the same and can be grouped together, adding their probabilities. 
   Product encipherment is often used; for example, one follows a substitu-tion by a transposition or a transposition by a Vigen`ere, or applies a code to the text and enciphers the result by substitution, transposition, fractionation, etc. 
   It may be noted that multiplication is not in general commutative (we do not always have RS=SR), although in special cases, such as substitution and transposition, it is. Since it represents an operation it is de?nitionally associative. That is, R(ST)=(RS)T=RST. Furthermore, we have the laws 
p(p?T + q ?R)+qS=pp?T + pq ?R + qS 
(weighted associative law for addition) 
T(pR+qS)=pTR+qTS
(pR+qS)T=pRT+qST
(right and left hand distributive laws) and 
p1T+p2T+p3R=(p1+p2)T+p3R
   It should be emphasized that these combining operations of addition and multiplication apply to secrecy systems as a whole. The product of two sys-tems TRshould not be confused with the product of the transformations in the systems TiRj, which also appears often in this work. The former TRis a secrecy system, i.e., a set of transformations with associated probabilities; the latter is a particular transformation. Further the sum of two systems pR+qTis a system—the sum of two transformations is not de?ned. The systems Tand Rmay commute without the individual Tiand Rjcommuting, e.g., if Ris a Beaufort system of a given period, all keys equally likely. 
RiRj?RjRi
= 
in general, but of course RRdoes not depend on its order; actually 
RR = V 
the Vigen`ere of the same period with random key. On the other hand, if the individual Tiand Rjof two systems Tand Rcommute, then the systems commute. 
   A system whose Mand Espaces can identi?ed, a very common case as when letter sequences are transformed into letter sequences, may be termed endomorphic. An endomorphic system Tmay be raised to a power Tn . 
   A secrecy system Twhose product with itself is equal to T, i.e., for which 
TT = T 
will be called idempotent. For example, simple substitution, transposition of period p, Vigen`ere of period p(all with each key equally likely) are idempo-tent. 
   The set of all endomorphic secrecy systems de?ned in a ?xed message space constitutes an “algebraic variety”, that is, a kind of algebra, using the operations of addition and multiplication. In fact, the properties of addition and multiplication which we have discussed may be summarized as follows: The set of endomorphic ciphers with the same message space and the two combining operations of weighted addition and multiplication form a linear associative algebra with a unit element, apart from the fact that the coef?-cients in a weighted addition must be non-negative and sum to unity. 
   The combining operations give us ways of constructing many new types of secrecy systems from certain ones, such as the examples given. We may also use them to describe the situation facing a cryptanalyst when attempting to solve a cryptogram of unknown type. He is, in fact, solving a secrecy system of the type 
T=p1A+p2B+···+prS+p?X ? p =1 
where the A,B,···,Sare known types of ciphers, with the pitheir a priori probabilities in this situation, and p?X corresponds to the possibility of a completely new unknown type of cipher. 
   PURE AND MIXED CIPHERS 
Certain types of ciphers such as the simple substitution, the transposition of a given period, the Vigen`ere of a given period, the mixed alphabet Vigen`ere, etc. (all with each key equally likely) have a certain homogeneity with re-spect to key. Whatever the key, the enciphering, deciphering and decrypting processes are essentially the same. This may be contrasted with the cipher 
pS + qT 
where Sis a simple substitution and Ta transposition of a given period. In this case the entire system changes for enciphering, deciphering and decrypt-ment, depending on whether the substitution or transposition is used. 
   The cause of the homogeneity in these systems stems from the group property–we notice that, in the above examples of homogeneous ciphers, the product TiTjof any two transformations in the set is equal to a third transfor-mation Tkin the set. On the other hand TiSjjust does not equal any transfor-mation in the cipher 
pS + qT 
which contains only substitutions and transpositions, no products. 
   We might de?ne a “pure” cipher, then, as one whose Tiform a group. This, however, would be too restrictive since it requires that the Espace be the same as the Mspace, i.e., that the system be endomorphic. The fractional transposition is homogeneous as the ordinary transposition without being en-domorphic. The proper de?nition is the following: A cipher Tis pure if for every Ti,Tj,Tkthere is a Tssuch that 
TiTj ?1Tk = Ts 
and every key is equally likely. Otherwise the cipher is mixed. The systems of Fig. 2 are mixed. Fig. 4 is pure if all keys are equally likely. 
Theorem 1. In a pure cipher the operations Ti ?1Tjwhich transform the mes-sage space into itself form a group whose order is m, the number of different keys. 
For 
Tj ?1TkTk ?1Tj = I 
so that each element has an inverse. The associative law is true since these are operations, and the group property follows from 
Ti ?1TjTk ?1Tl = T s ?1TkTk ?1Tl = T s ?1Tl 
using our assumption that Ti ?1Tj = Ts ?1Tkfor some s. 
   The operation Ti ?1Tjmeans, of course, enciphering the message with key jand then deciphering with key iwhich brings us back to the message space. If Tis endomorphic, i.e., the Tithemselves transform the space ?Minto itself (as is the case with most ciphers, where both the message space and the cryptogram space consist of sequences of letters), and the Tiare a group and equally likely, then Tis pure, since 
TiTj ?1Tk = TiTr = Ts. 
Theorem 2. The product of two pure ciphers which commute is pure. 
For if Tand Rcommute TiRj=RlTmfor every i,jwith suitable l,m, and 
TiRj(TkRl)?1TmRn = TiRjRl ?1Tk ?1TmRn 
= RuRv ?1RwTrT s ?1Tl 
=RhTg.
The commutation condition is not necessary, however, for the product to be a pure cipher. 
   A system with only one key, i.e., a single de?nite operation T1, is pure since the only choice of indices is 
T1T1 ?1T1=T1.
Thus the expansion of a general cipher into a sum of such simple transforma-tions also exhibits it as a sum of pure ciphers. 
   An examination of the example of a pure cipher shown in Fig. 4 discloses certain properties. The messages fall into certain subsets which we will call residue classes, and the possible cryptograms are divided into corresponding residue classes. There is at least one line from each message in a class to each cryptogram in the corresponding class, and no line between classes which do not correspond. The number of messages in a class is a divisor of the total number of keys. The number of lines “in parallel” from a message Mto a cryptogram in the corresponding class is equal to the number of keys divided by the number of messages in the class containing the message (or cryptogram). It is shown in the appendix that these hold in general for pure ciphers. Summarized formally, we have: 
MESSAGE CRYPTOGRAM RESIDUE RESIDUE 


PURE SYSTEM 
Fig. 4. Pure system 
Theorem 3. In a pure system the messages can be divided into a set of “residue classes” C1,C2,···,Csand the cryptograms into a corresponding set of residue classes C1? ,C2? ,···,Cs ? with the following properties: 
  (1) The message residue classes are mdually exclusive and collectively con-tain all possible messages. Similarly for the cryptogram residue classes. 
  (2) Enciphering any message in Ciwith any key produces a cryptogram in C?. Deciphering any cryptogram in C? with any key leads to a message in 

  iiCi.
  (3) The number of messages in Ci, say ?i, is equal to the number of cryp-tograms in Ci ? and is a divisor of kthe number of keys. 
  (4) Each message in Cican be enciphered into each cryptogram in Ci ? by exactly ?k i different keys. Similarly for decipherment. 

   The importance of the concept of a pure cipher (and the reason for the name) lies in the fact that in a pure cipher all keys are essentially the same. Whatever key is used for a particular message, the a posteriori probabilities of all messages are identical. To see this, note that two different keys ap-plied to the same message lead to two cryptograms in the same residue class, say Ci?. The two cryptograms therefore could each be deciphered by ?k i keys into each message in Ciand into no other possible messages. All keys being equally likely the a posteriori probabilities of various messages are thus 
P(M)PM(E)P(M)PM(E)P(M)
PE(M)==? = 
P(E)M P(M)PM(E)P(Ci)
where Mis in Ci, Eis in Ci ? and the sum is over all messages in Ci. If Eand Mare not in corresponding residue classes, PE(M)=0. Similarly it can be shown that the a posteriori probabilities of the different keys are the same in value but these values are associated with different keys when a different key is used. The same set of values of PE(K)have undergone a permutation among the keys. Thus we have the result 
Theorem 4. In a pure system the a posteriori probabilities of various mes-sages PE(M)are independent of the key that is chosen. The a posteriori prob-abilities of the keys PE(K)are the same in value but undergo a permutation with a different key choice. 
   Roughly we may say that any key choice leads to the same cryptanalytic problem in a pure cipher. Since the different keys all result in cryptograms in the same residue class this means that all cryptograms in the same residue class are cryptanalytically equivalent–they lead to the same a posteriori prob-abilities of messages and, apart from a permutation, the same probabilities of keys. 
   As an example of this, simple substitution with all keys equally likely is a pure cipher. The residue class corresponding to a given cryptogram Eis the set of all cryptograms that may be obtained from E by operations TiTk ?1E. In this case TiTk ?1 is itself a substitution and hence any substitution on Egives another member of the same residue class. Thus, if the cryptogram is 
E=XCPPGCFQ,
then 
E1=RDHHGDSNE2=ABCCDBEF
676 
etc. are in the same residue class. It is obvious in this case that these cryp-tograms are essentially equivalent. All that is of importance in a simple sub-stitution with random key is the pattern of letter repetitions the actual letters being dummy variables. Indeed we might dispense with them entirely, indi-cating the pattern of repetitions in Eas follows: 
This notation describes the residue class but eliminates all information as to the speci?c member of the class. Thus it leaves precisely that information which is cryptanalytically pertinent. This is related to one method of attack-ing simple substitution ciphers—the method of pattern words. 
   In the Caesar type cipher only the ?rst differences mod 26 of the cryptogram are signi?cant. Two cryptograms with the same ?eiare in the same residue class. One breaks this cipher by the simple process of writing down the 26 members of the message residue class and picking out the one which makes sense. 
   The Vigen`ere of period dwith random key is another example of a pure cipher. Here the message residue class consists of all sequences with the same ?rst differences as the cryptogram, for letters separated by distance d. For d=3the residue class is de?ned by 
m1— m4=c1— c4m2— m5=c2— c5m3— m6=c3— c6m4— m7=c4— c7
. . . 
where E=e1,e2,···is the cryptogram and m1,m2,···is any Min the corresponding residue class. 
   In the transposition cipher of period dwith random key, the residue class consists of all arrangements of the eiin which no eiis moved out of its block of length d, and any two eiat a distance dremain at this distance. This is used in breaking these ciphers as follows: The cryptogram is written in successive blocks of length d, one under another as below (d=5): 
e1e2e3e4e5e6e7e8e9e10e11e12... . . ... 
The columns are then cut apart and rearranged to make meaningful text. When the columns are cut apart, the only information remaining is the residue class of the cryptogram. 
Theorem 5. If Tis pure then TiTj ?1T=Twhere TiTjare any two transfor-mations of T. Conversely if this is true for any TiTjin a system Tthen Tis pure. 
   The ?rst part of this theorem is obvious from the de?nition of a pure system. To prove the second part we note ?rst that, if TiTj ?1T=T, then TiTj ?1Tsis a transformation of T. It remains to show that all keys are equiprobable. We have T=? s psTsand 
? psTiTj ?1Ts = ? psTsssThe term in the left hand sum with s=jyields pjTi. The only term in Tion the right is piTi. Since all coef?cients are nonnegative it follows that pj?pi.The same argument holds with iand jinterchanged and consequently pj=piand Tis pure. Thus the condition that TiTj ?1T = T might be used as an alternative de?nition of a pure system. 
   SIMILAR SYSTEMS 
Two secrecy systems Rand Swill be said to be similar if there exists a transformation Ahaving an inverse A?1 such that 
                           R=ASThis means that enciphering with Ris the same as enciphering with Sand then operating on the result with the transformation A. If we write R?Sto mean Ris similar to Sthen it is clear that R?Simplies S?R. Also R?Sand S?Timply R?Tand ?nally R?R. These are summarized by saying that similarity is an equivalence relation. 
   The cryptographic signi?cance of similarity is that if R?Sthen Rand Sare equivalent from the cryptanalytic point of view. Indeed if a cryptanalyst intercepts a cryptogram in system She can transform it to one in system Rby merely applying the transformation Ato it. A cryptogram in system Ris transformed to one in Sby applying A?1. If Rand Sare applied to the same language or message space, there is a one-to-one correspondence between the resulting cryptograms. Corresponding cryptograms give the same distribution of a posteriori probabilities for all messages. 
   If one has a method of breaking the system Rthen any system Ssimilar to Rcan be broken by reducing to Rthrough application of the operation A. This is a device that is frequently used in practical cryptanalysis. 
   As a trivial example, simple substitution where the substitutes are not let-ters but arbitrary symbols is similar to simple substitution using letter sub-stitutes. A second example is the Caesar and the reverse Caesar type ci-phers. The latter is sometimes broken by ?rst transforming into a Caesar type. This can be done by reversing the alphabet in the cryptogram. The Vigen`ere, Beaufort and Variant Beaufort are all similar, when the key is ran-dom. The “autokey” cipher (with the message used as “key”) primed with the key K1K2···Kdis similar to a Vigen`ere type with the key alternately added and subtracted Mod 26. The transformation Ain this case is that of “deciphering” the autokey with a series of dA’s for the priming key. 
PART IITHEORETICAL SECRECY
9 INTRODUCTION 
We now consider problems connected with the “theoretical secrecy” of a sys-tem. How immune is a system to cryptanalysis when the cryptanalyst has un-limited time and manpower available for the analysis of cryptograms? Does a cryptogram have a unique solution (even though it may require an imprac-tical amount of work to ?nd it) and if not how many reasonable solutions does it have? How much text in a given system must be intercepted before the solution becomes unique? Are there systems which never become unique in solution no matter how much enciphered text is intercepted? Are there systems for which no information whatever is given to the enemy no matter how much text is intercepted? In the analysis of these problems the concepts of entropy, redundancy and the like developed in “A Mathematical Theory of Communication” (hereafter referred to as MTC) will ?nd a wide application. 
10 PERFECT SECRECY 
Let us suppose the possible messages are ?nite in number M1,···,Mnand have a priori probabilities P(M1),···,P(Mn), and that these are enciphered into the possible cryptograms E1,···,Emby 
E=TiM.
   The cryptanalyst intercepts a particular Eand can then calculate, in prin-ciple at least, the  a posteriori probabilities for the various messages, PE(M). It is natural to de?ne perfect secrecy by the condition that, for all Ethe a posteriori probabilities are equal to the a priori probabilities independently of the values of these. In this case, intercepting the message has given the cryptanalyst no information.9 Any action of his which depends on the infor-mation contained in the cryptogram cannot be altered, for all of his proba-bilities as to what the cryptogram contains remain unchanged. On the other hand, if the condition is not satis?ed there will exist situations in which the enemy has certain a priori probabilities, and certain key and message choices may occur for which the enemy’s probabilities do change. This in turn may affect his actions and thus perfect secrecy has not been obtained. Hence the de?nition given is necessarily required by our intuitive ideas of what perfect secrecy should mean. 
   A necessary and suf?cient condition for perfect secrecy can be found as follows: We have by Bayes’ theorem 
P(M)PM(E)
PE(M)=
P(E)
in which: P(M)= a priori probability of message M. PM(E)= conditional probability of cryptogram Eif message Mis chosen i.e. the sum of the probabilities of all keys which produce cryptogram Efrom message M. P(E)= probability of obtaining cryptogram Efrom any cause. PE(M)= a posteriori probability of message Mif cryptogram Eis intercepted. For perfect secrecy PE(M)must equal P(M)for all Eand all M. Hence either P(M)=0, a solution that must be excluded since we demand the equality independent of the values of P(M), or 
PM(E)=P(E)
for every M and E. Conversely if PM(E)=P(E)then 
PE(M)=P(M)
and we have perfect secrecy. Thus we have the result: 
Theorem 6. A necessary and suf?cient condition for perfect secrecy is that 
PM(E)=P(E)
for all Mand E. That is, PM(E)must be independent of M. 
Stated another way, the total probability of all keys that transform Mi 
9 A purist might object that the enemy has obtained some information in that he knows a message was sent. This may be answered by having among the messages a “blank” corresponding to “no message.” If no message is originated the blank is enciphered and sent as a cryptogram. Then even this modicum of remaining information is eliminated. 
into a given cryptogram E is equal to that of all keys transforming Mjinto the same E, for all Mi,Mjand E. 
   Now there must be as many E’s as there are M’s since, for a ?xed i, Tigives a one-to-one correspondence between all the M’s and some of the E’s. For perfect secrecy PM(E)=P(E)?0for any of these E’s and any M.
                               =Hence there is at least one key transforming any Minto any of these E’s. But all the keys from a ?xed Mto different E’s must be different, and therefore the number of different keys is at least as great as the number of M’s. It is possible to obtain perfect secrecy with only this number of keys, as 

Fig. 5. Perfect system 
one shows by the following example: Let the Mibe numbered 1 to nand the Eithe same, and using nkeys let 
                          TiMj=Eswhere s=i+j(Modn). In this case we see that PE(M)=n 1 
                                                      = P(E)and we have perfect secrecy. An example is shown in Fig. 5 with s=i+j?1(Mod5). 
   Perfect systems in which the number of cryptograms, the number of mes-sages, and the number of keys are all equal are characterized by the proper-ties that (1) each Mis connected to each Eby exactly one line, (2) all keys are equally likely. Thus the matrix representation of the system is a “Latin square”. 
   In MTC it was shown that information may be conveniently measured by means of entropy. If we have a set of possibilities with probabilities p1,p2,···,pn, the entropy His given by: 
H=?pilogpi.
681 
In a secrecy system there are two statistical choices involved, that of the mes-sage and of the key. We may measure the amount of information produced when a message is chosen by H(M): 
H(M)=?P(M)logP(M),
the summation being over all possible messages. Similarly, there is an uncer-tainty associated with the choice of key given by: 
H(K)=?P(K)logP(K).
   In perfect systems of the type described above, the amount of information in the message is at most log n(occurring when all messages are equiprob-able). This information can be concealed completely only if the key uncer-tainty is at least log n. This is the ?rst example of a general principle which will appear frequently: that there is a limit to what we can obtain with a given uncertainty in key—the amount of uncertainty we can introduce into the so-lution cannot be greater than the key uncertainty. 
   The situation is somewhat more complicated if the number of messages is in?nite. Suppose, for example, that they are generated as in?nite sequences of letters by a suitable Markoff process. It is clear that no ?nite key will give perfect secrecy. We suppose, then, that the key source generates key in the same manner, that is, as an in?nite sequence of symbols. Suppose further that only a certain length of key LKis needed to encipher and decipher a length LMof message. Let the logarithm of the number of letters in the message alphabet be RMand that for the key alphabet be RK. Then, from the ?nite case, it is evident that perfect secrecy requires 
RMLM?RKLK.
This type of perfect secrecy is realized by the Vernam system. 
   These results have been deduced on the basis of unknown or arbitrary a priori probabilities of the messages. The key required for perfect secrecy depends then on the total number of possible messages. 
   One would expect that, if the message space has ?xed known statistics, so that it has a de?nite mean rate Rof generating information, in the sense of MTC, then the amount of key needed could be reduced on the average in just this ratio R , and this is indeed true. In fact the message can be passed 
RM 
through a transducer which eliminates the redundancy and reduces the ex-pected length in just this ratio, and then a Vernam system may be applied to the result. Evidently the amount of key used per letter of message is statisti-cally reduced by a factor RR M and in this case the key source and information source are just matched—a bit of key completely conceals a bit of message information. It is easily shown also, by the methods used in MTC, that this is the best that can be done. 
   Perfect secrecy systems have a place in the practical picture—they may be used either where the greatest importance is attached to complete secrecy— e.g., correspondence between the highest levels of command, or in cases where the number of possible messages is small. Thus, to take an extreme example, if only two messages “yes” or “no” were anticipated, a perfect sys-tem would be in order, with perhaps the transformation table: 
K
M A B yes 0 1 no 1 0 
   The disadvantage of perfect systems for large correspondence systems is, of course, the equivalent amount of key that must be sent. In succeeding sections we consider what can be achieved with smaller key size, in particular with ?nite keys. 
11 EQUIVOCATION 
Let us suppose that a simple substitution cipher has been used on English text and that we intercept a certain amount, Nletters, of the enciphered text. For Nfairly large, more than say 50letters, there is nearly always a unique solu-tion to the cipher; i.e., a single good English sequence which transforms into the intercepted material by a simple substitution. With a smaller N, however, the chance of more than one solution is greater: with N=15there will gen-erally be quite a number of possible fragments of text that would ?t, while with N=8a good fraction (of the order of 81 ) of all reasonable English sequences of that length are possible, since there is seldom more than one repeated letter in the 8. With N=1any letter is clearly possible and has the same a posteriori probability as its a priori probability. For one letter the system is perfect. 
   This happens generally with solvable ciphers. Before any material is in-tercepted we can imagine the a priori probabilities attached to the various possible messages, and also to the various keys. As material is intercepted, the cryptanalyst calculates the a posteriori probabilities; and as Nincreases the probabilities of certain messages increase, and, of most, decrease, until ?nally only one is left, which has a probability nearly one, while the total probability of all others is nearly zero. 
   This calculation can actually be carried out for very simple systems. Ta-ble 1 shows the a posteriori probabilities for a Caesar type cipher applied to English text, with the key chosen at random from the 26possibilities. To enable the use of standard letter, digram and trigram frequency tables, the text has been started at a random point (by opening a book and putting a pen-cil down at random on the page). The message selected in this way begins “creases to ...” starting inside the word increases. If the message were known to start a sentence a different set of probabilities must be used corresponding to the frequencies of letters, digrams, etc., at the beginning of sentences. 
Table 1. A Posteriori Probabilities for a Caesar Type Cryptogram 
Decipherments N = 1 N = 2 N = 3 N = 4 N = 5 C R E A S .028 .0377 .1111 .3673 1 D S F B T .038 .0314 E T G C U .131 .0881 F U H D V .029 .0189 G V I E W .020 H W J F X .053 .0063 I X K G Y .063 .0126 J Y L H Z .001 K Z M I A .004 L A N J B .034 .1321 .2500 M B O K C .025 .0222 N C P L D .071 .1195 O D Q M E .080 .0377 P E R N F .020 .0818 .4389 .6327 Q F S O G .001 R G T P H .068 .0126 S H U Q I .061 .0881 .0056 T I V R J .105 .2830 .1667 U J W S K .025 V K X T L .009 W L Y U M .015 .0056 X M Z V N .002 Y N A W O .020 Z O B X P .001 A P C Y Q .082 .0503 B Q D Z R .014 H(decimal digits) 1.2425 .9686 .6034 .285 0 
   The Caesar with random key is a pure cipher and the particular key chosen does not affect the a posteriori probabilities. To determine these we need merely list the possible decipherments by all keys and calculate their a priori probabilities. The a posteriori probabilities are these divided by their sum. These possible decipherments are found by the standard process of “running down the alphabet” from the message and are listed at the left. These form the residue class for the message. For one intercepted letter the a posteriori probabilities are equal to the a priori probabilities for letters10 and are shown in the column headed N=1. For two intercepted letters the probabilities are those for digrams adjusted to sum to unity and these are shown in the column N=2. 
10 The probabilities for this table were taken from frequency tables given by Fletcher Pratt in a book 
“Secret and Urgent” published by Blue Ribbon Books, New York, 1939. Although not complete, 
they are suf?cient for present purposes. 
684 
   Trigram frequencies have also been tabulated and these are shown in the column N=3. For four-and ?ve-letter sequences probabilities were ob-tained by multiplication from trigram frequencies since, roughly, 
p(ijkl)=p(ijk)pjk(l).
   Note that at three letters the ?eld has narrowed down to four messages of fairly high probability, the others being small in comparison. At four there are two possibilities and at ?ve just one, the correct decipherment. 
   In principle this could be carried out with any system but, unless the key is very small, the number of possibilities is so large that the work involved prohibits the actual calculation. 
   This set of a posteriori probabilities describes how the cryptanalyst’s knowledge of the message and key gradually becomes more precise as enci-phered material is obtained. This description, however, is much too involved and dif?cult to obtain for our purposes. What is desired is a simpli?ed de-scription of this approach to uniqueness of the possible solutions. 
   A similar situation arises in communication theory when a transmitted signal is perturbed by noise. It is necessary to set up a suitable measure of the uncertainty of what was actually transmitted knowing only the perturbed version given by the received signal. In MTC it was shown that a natural mathematical measure of this uncertainty is the conditional entropy of the transmitted signal when the received signal is known. This conditional en-tropy was called, for convenience, the equivocation. 
   From the point of view of the cryptanalyst, a secrecy system is almost identical with a noisy communication system. The message (transmitted sig-nal) is operated on by a statistical element, the enciphering system, with its statistically chosen key. The result of this operation is the cryptogram (analo-gous to the perturbed signal) which is available for analysis. The chief differ-ences in the two cases are: ?rst, that the operation of the enciphering trans-formation is generally of a more complex nature than the perturbing noise in a channel; and, second, the key for a secrecy system is usually chosen from a ?nite set of possibilities while the noise in a channel is more often continually introduced, in effect chosen from an in?nite set. 
   With these considerations in mind it is natural to use the equivocation as a theoretical secrecy index. It may be noted that there are two signi?cant equivocations, that of the key and that of the message. These will be denoted by HE(K)and HE(M)respectively. They are given by: 
HE(K)=P(E,K)logPE(K)E,K
HE(M)=P(E,M)logPE(K)E,M
in which E,Mand Kare the cryptogram, message and key and 
P(E,K)is the probability of key Kand cryptogram E
PE(K)is the a posteriori probability of key Kif cryptogram E
is intercepted. 
   P(E,M)and PE(M)are the similar probabilities for message in-
           stead of key. The summation in HE(K)is over all possible cryptograms of a certain length (say N letters) and over all keys. For HE(M)the summation is over all mes-sages and cryptograms of length N. Thus HE(K)and HE(M)are both func-tions of N, the number of intercepted letters. This will sometimes be indi-cated explicitly by writing HE(K,N)and HE(M,N). Note that these are “total” equivocations; i.e., we do not divide by Nto obtain the equivocation rate which was used in MTC. 
   The same general arguments used to justify the equivocation as a mea-sure of uncertainty in communication theory apply here as well. We note that zero equivocation requires that one message (or key) have unit probability, all other zero, corresponding to complete knowledge. Considered as a function of N, the gradual decrease of equivocation corresponds to increasing knowl-edge of the original key or message. The two equivocation curves plotted as functions of N, will be called the equivocation characteristics of the secrecy system in question. 
   The values of HE(K,N)and HE(M,N)for the Caesar type cryptogram considered above have been calculated and are given in the last row of Ta-ble 1. HE(K,N)and HE(M,N)are equal in this case and are given in dec-imal digits (i.e., the logarithmic base 10is used in the calculation). It should be noted that the equivocation here is for a particular cryptogram, the sum-mation being only over M(or K), not over E. In general the summation would be over all possible intercepted cryptograms of length Nand would give the average uncertainty. The computational dif?culties are prohibitive for this general calculation. 
12 PROPERTIES OF EQUIVOCATION 
Equivocation may be shown to have a number of interesting properties, most of which ?t into our intuitive picture of how such a quantity should behave. We will ?rst show that the equivocation of key or of a ?xed part of a message decreases when more enciphered material is intercepted. 
Theorem 7. The equivocation of key HE(K,N)is a non-increasing function of N. The equivocation of the ?rst Aletters of the message is a non-increasing function of the number Nwhich have been intercepted. If Nletters have been intercepted, the equivocation of the ?rst Nletters of message is less than or equal to that of the key. These may be written: 
HE(K,S)?HE(K,N)S?NHE(M,S)?HE(M,N)S?N(Hfor ?rst Aletters of text) HE(M,N)?HE(K,N)
   The quali?cation regarding Aletters in the second result of the theorem is so that the equivocation will be calculated with respect to the amount of message that has been intercepted. If it is, the message equivocation may (and usually does) increase for a time, due merely to the fact that more letters stand for a larger possible range of messages. The results of the theorem are what we might hope from a good secrecy index, since we would hardly expect to be worse off on the average after intercepting additional material than before. The fact that they can be proved gives further justi?cation to our use of the equivocation measure. 
   The results of this theorem are a consequence of certain properties of con-ditional entropy proved in MTC. Thus, to show the ?rst or second statements of Theorem 7, we have for any chance events Aand B
                        H(B)?HA(B).If we identify Bwith the key (knowing the ?rst Sletters of cryptogram) and Awith the remaining N?Sletters we obtain the ?rst result. Similarly identifying Bwith the message gives the second result. The last result follows from 
HE(M)?HE(K,M)=HE(K)+HE,K(M)
and the fact that HE,K(M)=0since Kand Euniquely determine M. Since the message and key are chosen independently we have: 
H(M,K)=H(M)+H(K).
Furthermore, 
             H(M,K)=H(E,K)=H(E)+HE(K),the ?rst equality resulting from the fact that knowledge of Mand Kor of Eand Kis equivalent to knowledge of all three. Combining these two we obtain a formula for the equivocation of key: 
                HE(K)=H(M)+H(K)?H(E).In particular, if H(M)=H(E)then the equivocation of key, HE(K), is equal to the a priori uncertainty of key, H(K). This occurs in the perfect systems described above. A formula for the equivocation of message can be found by similar means. We have 
H(M,E)=H(E)+HE(M)=H(M)+HM(E)
HE(M)=H(M)+HM(E)?H(E).
687 
   If we have a product system S=TR, it is to be expected that the second enciphering process will be decrease the equivocation of message. That this is actually true can be shown as follows: Let M,E1,E2be the message and the ?rst and second encipherments, respectively. Then 
PE1 E2 (M)=PE1 (M).
Consequently 
HE1 E2 (M)=HE1 (M).
Since, for any chance variables, x,y,z,Hxy(z)?Hy(z), we have the desired result, HE2 (M)?HE1 (M).Theorem 8. The equivocation in message of a product system S=TRis 
not less than that when only Ris used. 
   Suppose now we have a system Twhich can be written as a weighted sum of several systems R,S,···,U
T=p1R+p2S+···+pmUpi=1
and that systems R,S,···,Uhave equivocations H1,H2,H3,···,Hm. Theorem 9. The equivocation Hof a weighted sum of systems is bounded by the inequalities 
piHi?H?piHi?pilogpi.
These are best limits possible. The H’s may be equivocations either of key or message. 
   The upper limit is achieved, for example, in strongly ideal systems (to be described later) where the decomposition is into the simple transformations of the system. The lower limit is achieved if all the systems R,S,···,Ugo to completely different cryptogram spaces. This theorem is also proved by the general inequalities governing equivocation, 
HA(B)?H(B)?H(A)+HA(B).
We identify Awith the particular system being used and Bwith the key or message. 
   There is a similar theorem for weighted sums of languages. For this we identify Awith the particular language. Theorem 10. Suppose a system can be applied to languages L1,L2,···,Lmand has equivocation characteristics H1,H2,···,Hm. When applied to the weighted sum ?piLi, the equivocation His bounded by 
piHi?H?piHi?pilogpi.
688 
These limits are the best possible and the equivocations in question can be either for key or message. 
   The total redundancy DN for N letters of message is de?ned by 
DN=logG?H(M)
where Gis the total number of messages of length Nand H(M)is the uncer-tainty in choosing one of these. In a secrecy system where the total number of possible cryptograms is equal to the number of possible messages of length N,H(E)?logG. Consequently, 
HE(K)=H(K)+H(M)?H(E)?H(K)?[logG?H(M)].
Hence 
H(K)?HE(K)?DN.
This shows that, in a closed system, for example, the decrease in equivocation of key after Nletters have been intercepted is not greater than the redundancy of Nletters of the language. In such systems, which comprise the majority of ciphers, it is only the existence of redundancy in the original messages that makes a solution possible. 
   Now suppose we have a pure system. Let the different residue classes of messages be C1,C2,C3,···,Cr, and the corresponding set of residue classes of cryptograms be C1? ,C2? ,C3? ,···,Cr? . The probability of each Ein C1 ? is the same: 
P(E)=P (?Cii) Ea member of Ci
where ?iis the number of different messages in Ci. Thus we have 
? P(Ci)P(Ci)
H(E)=??ilog?i?i
i 
? P(Ci)
=?P(Ci)log?i
i 
Substituting in our equation for HE(K)we obtain: 
Theorem 11. For a pure cipher 
? P(Ci)
HE(K)=H(K)+H(M)+P(Ci)log.?i
i 
This result can be used to compute HE(K)in certain cases of interest. 689 
13EQUIVOCATION FOR SIMPLE SUBSTITUTION ON A TWO LETTER LANGUAGE 
We will now calculate the equivocation in key or message when simple sub-stitution is applied to a two letter language, with probabilities pand qfor 0and 1, and successive letters chosen independently. We have 
HE(M)=HE(K)=?P(E)PE(K)logPE(K)
The probability that Econtains exactly s0’s in a particular permutation is: 1
(p s q N?s+ q s p N?s)
2 

Fig. 6. Equivocation for simple substitution on two-letter language 
and the a posteriori probabilities of the identity and inverting substitutions (the only two in the system) are respectively: 
sN?sN?ss
pq	pq
PE(0)=PE(1)=
              (psqN?s+ qspN?s)(psqN?s+ qspN?s) There are ?N? terms for each sand hence 
s 
                          ??N? s psqN?sHE(K,N)=?pqN?slog . 
s(psqN?s+ qspN?s)s 
For p = 13 23 , and for p = 18 78
,q = ,q = 
                                , HE(K,N)has been calculated and is shown in Fig. 6. 
14THE EQUIVOCATION CHARACTERISTIC FOR A “RANDOM” CIPHER 
In the preceding section we have calculated the equivocation characteristic for a simple substitution applied to a two-letter language. This is about the simplest type of cipher and the simplest language structure possible, yet al-ready the formulas are so involved as to be nearly useless. What are we to do with cases of practical interest, say the involved transformations of a frac-tional transposition system applied to English with its extremely complex statistical structure? This complexity itself suggests a method of approach. Suf?ciently complicated problems can frequently be solved statistically. To facilitate this we de?ne the notion of a “random” cipher. 
   We make the following assumptions: 
 1. The number of possible messages of length Nis T=2R0 N , thus R0=
 log 2G, where Gis the number of letters in the alphabet. The number of possible cryptograms of length Nis also assumed to be T. 
2 The possible messages of length Ncan be divided into two groups: one group of high and fairly uniform a priori probability, the second group of negligibly small total probability. The high probability group will contain S=2RN messages, where R = H(NM) , that is, Ris the entropy of the message source per letter. 
3 The deciphering operation can be thought of as a series of lines, as in Figs. 2 and 4, leading back from each Eto various M’s. We assume kdifferent equiprobable keys so there will be klines leading back from each E. For the random cipher we suppose that the lines from each Ego back to a random selection of the possible messages. Actually, then, a random cipher is a whole ensemble of ciphers and the equivocation is the average equivocation for this ensemble. 

   The equivocation of key is de?ned by 
HE(K)=P(E)PE(K)logPE(K).
The probability that exactly mlines go back from a particular Eto the high probability group of messages is 
? k ??S ?m ? S ?k?m
1 ? 
mT T 
If a cryptogram with msuch lines is intercepted the equivocation is logm. The probability of such a cryptogram is mT , since it can be produced by m
SK 
keys from high probability messages each with probability TS 
                                                   . Hence the equivocation is: 
k ? ??S ?m??k?m
T ? k	S 
HE(K)=1?mlogm
Sk mT T 
m=1
We wish to ?nd a simple approximation to this when kis large. If the 
SK 
expected value of m, namely m=T ,i?1, the variation of logmover the range where the binomial distribution assumes large values will be small, and we can replace logmby logm. This can now be factored out of the summation, which then reduces to m. Hence, in this condition, 
. Sk 
HE(K)=log=logS?logT+logk
             THE(K)=.H(K)?DN,
where Dis the redundancy per letter of the original language (D=DN N ). If mis small compared to the large k, the binomial distribution can be approximated by a Poisson distribution: 
? k ? .e???mmk?m
pq = 
m	m! 
where ? = Sk . Hence 
T 
1 ? ?m 
HE(K)=.e ?? ? m log m. 
? 2 m! 
If we replace mby m+1, we obtain: 
HE(K)=.e ?? ? ?m log (m + 1). 
m!
1 
This may be used in the region where ?is near unity. For ??1, the only important term in the series is that for m=1; omitting the others we have: 
HE(K)=.e ??? log 2 . 
= ? log 2 .
=2?NDk log 2. 
   To summarize: HE(K), considered as a function of N, the number of intercepted letters, starts off at H(K)when N=0. It decreases linearly with 
H(K)
a slope ?Dout to the neighborhood of N=D . After a short transition region, HE(K)follows an exponential with “half life” distance D 1 if D is measured in bits per letter. This behavior is shown in Fig. 7, together with the approximating curves. 
   By a similar argument the equivocation of message can be calculated. It is 
HE(M)=R0Nfor R0N?HE(K)HE(M)=HE(K)for R0N?HE(K)HE(M)=HE(K)??(N)for R0N?HE(K)
where ?(N)is the function shown in Fig. 7 with Nscale reduced by factor of D . Thus, HE(M)rises linearly with slope R0, until it nearly intersects 
R0 

Fig. 7. Equivocation for random cipher 
the HE(K)line. After a rounded transition it follows the HE(K)curve down. 
   It will be seen from Fig. 7 that the equivocation curves approach zero rather sharply. Thus we may, with but little ambiguity, speak of a point at which the solution becomes unique. This number of letters will be called the unicity distance. For the random cipher it is approximately H(K).
D 
15 APPLICATION TO STANDARD CIPHERS 
Most of the standard ciphers involve rather complicated enciphering and deciphering operations. Furthermore, the statistical structure of natural lan-guages is extremely involved. It is therefore reasonable to assume that the formulas derived for the random cipher may be applied in such cases. It is necessary, however, to apply certain corrections in some cases. The main points to be observed are the following: 
1 We assumed for the random cipher that the possible decipherments of a cryptogram are a random selection from the possible messages. While not strictly true in ordinary systems, this becomes more nearly the case as the complexity of the enciphering operations and of the language structure increases. With a transposition cipher it is clear that letter frequencies are preserved under decipherment operations. This means that the possible decipherments are chosen from a more limited group, not the entire message space, and the formula should be changed. In place of R0one uses R1the entropy rate for a language with independent letters but with the regular letter frequencies. In some other cases a de?nite tendency toward returning the decipherments to high probability messages can be seen. If there is no clear tendency of this sort, and the system is fairly complicated, then it is reasonable to use the random cipher analysis. 
2 In many cases the complete key is not used in enciphering short mes-sages. For example, in a simple substitution, only fairly long messages will contain all letters of the alphabet and thus involve the complete key. Obviously the random assumption does not hold for small Nin such a case, since all the keys which differ only in the letters not yet appearing in the cryptogram lead back to the same message and are not randomly distributed. This error is easily corrected to a good approximation by the use of a “key appearance characteristic”. One uses, at a particular N, the effective amount of key that may be expected with that length of cryp-togram. For most ciphers, this is easily estimated. 
3 There are certain “end effects” due to the de?nite starting of the message which produce a discrepancy from the random characteristics. If we take a random starting point in English text, the ?rst letter (when we do not observe the preceding letters) has a possibility of being any letter with the ordinary letter probabilities. The next letter is more completely speci?ed since we then have digram frequencies. This decrease in choice value continues for some time. The effect of this on the curve is that the straight line part is displaced and approached by a curve depending on how much the statistical structure of the language is spread out over adjacent letters. As a ?rst approximation the curve can be corrected by shifting the line over to the half redundancy point—i.e., the number of letters where the language redundancy is half its ?nal value. 

   If account is taken of these three effects, reasonable estimates of the equivocation characteristic and unicity point can be made. The calculation can be done graphically as indicated in Fig. 8. One draws the key appearance characteristic and the total redundancy curve  DN (which is usually suf?ciently well represented by the line ND?). The difference between these out to the neighborhood of their intersection is HE(M). With a simple sub-stitution cipher applied to English, this calculation gave the curves shown in Fig. 9. The key appearance characteristic in this case was estimated by count-ing the number of different letters appearing in typical English passages of Nletters. In so far as experimental data on simple substitution could be found, they agree very well with the curves of Fig. 9, considering the various ideal-izations and approximations which have been made. For example, the unicity point, at about 27letters, can be shown experimentally to lie between the 

Fig. 8. Graphical calculation of equivocation 
limits 20and 30. With 30letters there is nearly always a unique solution to a cryptogram of this type and with 20it is usually easy to ?nd a number of solutions. 
   With transposition of period d(random key), H(K)=logd!, or about dlogde (using a Stirling approximation for d!). If we take .6decimal digits per letter as the appropriate redundancy, remembering the preservation of letter frequencies, we obtain about 1.7dlogde as the unicity distance. This also checks fairly well experimentally. Note that in this case HE(M)is de?ned only for integral multiples of d. 
   With the Vigen`ere the unicity point will occur at about 2dletters, and this too is about right. The Vigen`ere characteristic with the same key size as 

Fig. 9. Equivocation for simple substitution on English 
696 697 


simple substitution will be approximately as show in Fig. 10. The Vigen`ere, Playfair and Fractional cases are more likely to follow the theoretical formu-las for random ciphers than simple substitution and transposition. The reason for this is that they are more complex and give better mixing characteristics to the messages on which they operate. 
   The mixed alphabet Vigen`ere (each of dalphabets mixed independently and used sequentially) has a key size, 
                    H(K)=dlog26!=26.3dand its unicity point should be at about 53dletters. These conclusions can also be put to a rough experimental test with the Caesar type cipher. In the particular cryptogram analyzed in Table 1, section 11, the function HE(K,N)has been calculated and is given below, together with the values for a random cipher. 
    NH(observed) 1.411.24.97.60.280H(calculated) 1.411.25.98.54.15.03
   The agreement is seen to be quite good, especially when we remember that the observed Hshould actually be the average of many different cryp-tograms, and that Hfor the larger values of Nis only roughly estimated. 
   It appears then that the random cipher analysis can be used to estimate equivocation characteristics and the unicity distance for the ordinary types of ciphers. 
16 VALIDITY OF A CRYPTOGRAM SOLUTION 
The equivocation formulas are relevant to questions which sometimes arise in cryptographic work regarding the validity of an alleged solution to a cryp-togram. In the history of cryptography there have been many cryptograms, or possible cryptograms, where clever analysts have found a “solution”. It involved, however, such a complex process, or the material was so meager that the question arose as to whether the cryptanalyst had “read a solution” into the cryptogram. See, for example, the Bacon-Shakespeare ciphers and the “Roger Bacon” manuscript.11 
   In general we may say that if a proposed system and key solves a cryp-togram for a length of material considerably greater than the unicity distance the solution is trustworthy. If the material is of the same order of shorter than the unicity distance the solution is highly suspicious. 
   This effect of redundancy in gradually producing a unique solution to a cipher can be thought of in another way which is helpful. The redundancy is essentially a series of conditions on the letters of the message, which insure 
11 See Fletcher Pratt, loc. cit. 
that it be statistically reasonable. These consistency conditions produce cor-responding consistency conditions in the cryptogram. The key gives a certain amount of freedom to the cryptogram but, as more and more letters are in-tercepted, the consistency conditions use up the freedom allowed by the key. Eventually there is only one message and key which satis?es all the condi-tions and we have a unique solution. In the random cipher the consistency conditions are, in a sense “orthogonal” to the “grain of the key” and have their full effect in eliminating messages and keys as rapidly as possible. This is the usual case. However, by proper design it is possible to “line up” the redundancy of the language with the “grain of the key” in such a way that the consistency conditions are automatically satis?ed and HE(K)does not approach zero. These “ideal” systems, which will be considered in the next section, are of such a nature that the transformations Ti all induce the same probabilities in the E space. 
17 IDEAL SECRECY SYSTEMS 
We have seen that perfect secrecy requires an in?nite amount of key if we allow messages of unlimited length. With a ?nite key size, the equivocation of key and message generally approaches zero, but not necessarily so. In fact it is possible for HE(K)to remain constant at its initial value H(K). Then, no matter how much materials is intercepted, there is not a unique solution but many of comparable probability. We will de?ne an “ideal” system as one in which HE(K)and HE(M)do not approach zero as N??. A “strongly ideal” system is one in which HE(K)remains constant at H(K). 
   An example is a simple substitution on an arti?cial language in which all letters are equiprobable and successive letters independently chosen. It is easily seen that HE(K)=H(K)and HE(M)rises linearly along a line of slope logG(where Gis the number of letters in the alphabet) until it strikes the line H(K), after which it remains constant at this value. 
   With natural languages it is in general possible to approximate the ideal characteristic—the unicity point can be made to occur for as large Nas is desired. The complexity of the system needed usually goes up rapidly when we attempt to do this, however. It is not always possible to attain actually the ideal characteristic with any system of ?nite complexity. 
   To approximate the ideal equivocation, one may ?rst operate on the mes-sage with a transducer which removes all redundancies. After this almost any simple ciphering system—substitution, transposition, Vigen`ere, etc., is satis-factory. The more elaborate the transducer and the nearer the output is to the desired form, the more closely will the secrecy system approximate the ideal characteristic. 
Theorem 12. A necessary and suf?cient condition that Tbe strongly ideal is that, for any two keys, Ti ?1Tj is a measure preserving transformation of the message space into itself. 
   This is true since the a posteriori probability of each key is equal to its a priori probability if and only if this condition is satis?ed. 
18EXAMPLES OF IDEAL SECRECY SYSTEMS 
Suppose our language consists of a sequence of letters all chosen indepen-dently and with equal probabilities. Then the redundancy is zero, and from a result of section 12, HE(K)=H(K). We obtain the result 
Theorem 13. If all letters are equally likely and independent any closed ci-pher is strongly ideal. 
   The equivocation of message will rise along the key appearance charac-teristic which will usually approach H(K), although in some cases it does not. In the cases of n-gram substitution, transposition, Vigen`ere, and varia-tions, fractional, etc., we have strongly ideal systems for this simple language with HE(M)?H(K)as N??. 
Ideal secrecy systems suffer from a number of disadvantages. 
1 The system must be closely matched to the language. This requires an extensive study of the structure of the language by the designer. Also a change in statistical structure or a selection from the set of possible mes-sages, as in the case of probable words (words expected in this particular cryptogram), renders the system vulnerable to analysis. 
2 The structure of natural languages is extremely complicated, and this im-plies a complexity of the transformations required to eliminate redun-dancy. Thus any machine to perform this operation must necessarily be quite involved, at least in the direction of information storage, since a “dictionary” of magnitude greater than that of an ordinary dictionary is to be expected. 
3 In general, the transformations required introduce a bad propagation of error characteristic. Error in transmission of a single letter produces a region of changes near it of size comparable to the length of statistical effects in the original language. 

19FURTHER REMARKS ON EQUIVOCATION AND REDUNDANCY 
We have taken the redundancy of “normal English” to be about .7decimal digits per letter or a redundancy of 50%. This is on the assumption that word divisions were omitted. It is an approximate ?gure based on statistical struc-ture extending over about 8letters, and assumes the text to be of an ordi-nary type, such as newspaper writing, literary work, etc. We may note here a method of roughly estimating this number that is of some cryptographic interest. 
   A running key cipher is a Vernam type system where, in place of a random sequence of letters, the key is a meaningful text. Now it is known that running key ciphers can usually be solved uniquely. This shows that English can be reduced by a factor of two to one and implies a redundancy of at least 50%. This ?gure cannot be increase very much, however, for a number of reasons, unless long range “meaning” structure of English is considered. 
   The running key cipher can be easily improved to lead to ciphering sys-tems which could not be solved without the key. If one uses in place of one English text, about ddifferent texts as key, adding them all to the message, a suf?cient amount of key has been introduced to produce a high positive equivocation. Another method would be to use, say, every 10th letter of the text as key. The intermediate letters are omitted and cannot be used at any other point of the message. This has much the same effect, since these spaced letters are nearly independent. 
   The fact that the vowels in a passage can be omitted without essential loss suggests a simple way of greatly improving almost any ciphering sys-tem. First delete all vowels, or as much of the messages as possible without running the risk of multiple reconstructions, and then encipher the residue. Since reduces the redundancy by a factor of perhaps 3 or 4 to 1, the unic-ity point will be moved out by this factor. This is one way of approaching ideal systems—using the decipherer’s knowledge of English as part of the deciphering system. 
20 DISTRIBUTION OF EQUIVOCATION 
A more complete description of a secrecy system applied to a language than is afforded by the equivocation characteristics can be founded by giving the distribution of equivocation. For Nintercepted letters we consider the frac-tion of cryptograms for which the equivocation (for these particular E’s, not the mean HE(M)lies between certain limits. This gives a density distribution function 
P(HE(M),N)dHE(M)
for the probability that for Nletters Hlies between the limits Hand H+dH. The mean equivocation we have previously studied is the mean of this distribution. The function P(HE(M),N)can be thought of as plotted along a third dimension, normal to the paper, on the HE(M),Nplane. If the language is pure, with a small in?uence range, and the cipher is pure, the function will usually be a ridge in this plane whose highest point follows approximately the mean HE(M), at least until near the unicity point. In this case, or when the conditions are nearly veri?ed, the mean curve gives a reasonably complete picture of the system. 
   On the other hand, if the language is not pure, but made up of a set of pure components 
L=piLi
having different equivocation curves with the system, then the total distribu-tion will usually be made up of a series of ridges. There will be one for each Liweighted in accordance with its pi. The mean equivocation characteristic will be a line somewhere in the midst of these ridges and may not give a very complete picture of the situation. This is shown in Fig. 11. A similar effect occurs if the system is not pure but made up of several systems with different Hcurves. 
   The effect of mixing pure languages which are near to one another in statistical structure is to increase the width of the ridge. Near the unicity 

L1 + L2 
point this tends to raise the mean equivocation, since equivocation cannot become negative and the spreading is chie?y in the positive direction. We expect, therefore, that in this region the calculations based on the random cipher should be somewhat low. 
PART IIIPRACTICAL SECRECY
21 THE WORK CHARACTERISTIC 
After the unicity point has been passed in intercepted material there will usu-ally be a unique solution to the cryptogram. The problem of isolating this single solution of high probability is the problem of cryptanalysis. In the re-gion before the unicity point we may say that the problem of cryptanalysis is that of isolating all the possible solutions of high probability (compared to the remainder) and determining their various probabilities. 
   Although it is always possible in principle to determine these solutions (by trial of each possible key for example), different enciphering systems show a wide variation in the amount of work required. The average amount of work to determine the key for a cryptogram of Nletters, W(N), mea-sured say in man hours, may be called the work characteristic of the system. This average is taken over all messages and all keys with their appropriate probabilities. The function W(N)is a measure of the amount of “practical secrecy” afforded by the system. 
   For a simple substitution on English the work and equivocation charac-teristics would be somewhat as shown in Fig. 12. The dotted portion of 

the curve is in the range where there are numerous possible solutions and these must all be determined. In the solid portion after the unicity point only one solution exists in general, but if only the minimum necessary data are given a great deal of work must be done to isolate it. As more material is available the work rapidly decreases toward some asymptotic value—where the additional data no longer reduces the labor. 
   Essentially the behavior shown in Fig. 12 can be expected with any type of secrecy system where the equivocation approaches zero. The scale of man hours required, however, will differ greatly with different types of ciphers, even when the HE(M)curves are about the same. A Vigen`ere or compound Vigen`ere, for example, with the same key size would have a much better (i.e., 
much higher) work characteristic. A good practical secrecy system is one in which the W(N)curve remains suf?ciently high, out to the number of letters one expects to transmit with the key, to prevent the enemy from actually carrying out the solution, or to delay it to such an extent that the information is then obsolete. 
   We will consider in the following sections ways of keeping the function W(N)large, even though HE(K)may be practically zero. This is essentially a “max min” type of problem as is always the case when we have a battle of wits.12 In designing a good cipher we must maximize the minimum amount of work the enemy must do to break it. It is not enough merely to be sure none of the standard methods of cryptanalysis work—we must be sure that no method whatever will break the system easily. This, in fact, has been the weakness of many systems; designed to resist all the known methods of solution they later give rise to new cryptanalytic techniques which rendered them vulnerable to analysis. 
   The problem of good cipher design is essentially one of ?nding dif?cult problems, subject to certain other conditions. This is a rather unusual situa-tion, since one is ordinarily seeking the simple and easily soluble problems in a ?eld. 
   How can we ever be sure that a system which is not ideal and therefore has a unique solution for suf?ciently large Nwill require a large amount of work to break with every method of analysis? There are two approaches to this problem; (1) We can study the possible methods of solution available to the cryptanalyst and attempt to describe them in suf?ciently general terms to cover any methods he might use. We then construct our system to resist this “general” method of solution. (2) We may construct our cipher in such a way that breaking it is equivalent to (or requires at some point in the process) the solution of some problem known to be laborious. Thus, if we could show that solving a certain system requires at least as much work as solving a system of simultaneous equations in a large number of unknowns, of a complex type, then we would have a lower bound of sorts for the work characteristic. 
   The next three sections are aimed at these general problems. It is dif?-cult to de?ne the pertinent ideas involved with suf?cient precision to obtain results in the form of mathematical theorems, but it is believed that the con-clusions, in the form of general principles, are correct. 
12 See von Neumann and Morgenstern, loc. cit. The situation between the cipher designer and crypt-
analyst can be thought as a “game” of a very simple structure; a zero-sum two person game with 
complete information, and just two “moves”. The cipher designer chooses a system for his “move”. 
Then the cryptanalyst is informed of this choice and chooses a method of analysis. The “value” of 
the play is the average work required to break a cryptogram in the system by the method chosen. 
22GENERALITIES ON THE SOLUTION OF CRYPTOGRAMS 
After the unicity distance has been exceeded in intercepted material, any sys-tem can be solved in principle by merely trying each possible key until the unique solution is obtained—i.e., a deciphered message which “make sense” in the original language. A simple calculation shows that this method of so-lution (which we may call complete trial and error) is totally impractical except when the key is absurdly small. 
   Suppose, for example, we have a key of 26!possibilities or about 26.3decimal digits, the same size as in simple substitution on English. This is, by any signi?cant measure, a small key. It can be written on a small slip of paper, or memorized in a few minutes. It could be registered on 27switches, each having ten positions, or on 88two-position switches. 
   Suppose further, to give the cryptanalyst every possible advantage, that he constructs an electronic device to try keys at the rate of one each microsecond (perhaps automatically selecting from the results of a ?2 test for statistical signi?cance). He may expect to reach the right key about half way through, and after an elapsed time of about 2×1026/2×602×24×365×106 or 3×1012 years. 
   In other words, even with a small key complete trial and error will never used in solving cryptograms, except in the trivial case where the key is ex-tremely small, e.g., the Caesar with only 26possibilities, or 1.4digits. The trial and error which is used so commonly in cryptography is of a different sort, or is augmented by other means. If one had a secrecy system which re-quired complete trial and error it would be extremely safe. Such a system would result, it appears, if the meaningful original messages, all say of 1000 letters, were a random selection from the set of all sequences of 1000 letters. If any of the simple ciphers were applied to this type of language it seems that little improvement over complete trial and error would be possible. 
   The methods of cryptanalysis actually used often involved a great deal of trial and error, but in a different way. First, the trials progress from more probable to less probable hypotheses, and, second, each trial disposes of a large group of keys, not a single one. Thus the key space may be divided into say 10 subsets, each containing about the same number of keys. By at most 10 trials one determines which subset is the correct one. This subset is then divided into several secondary subsets and the process repeated. With the same key size (26!=. 2 × 1026 we would expect about 26×5or 130trials as compared to 1026 by complete trial and error. The possibility of choosing the most likely of the subsets ?rst for test would improve this result even more. If the divisions were into two compartments (the best way to minimize the number of trials) only 88trials would be required. Whereas complete trial and error requires trials to the order of the number of keys, this subdividing trial and error requires only trials to the order of the key size in bits. 
   This remains true even when the different keys have different probabili-ties. The proper procedure, then, to minimize the expected number of trials is to divide the key space into subsets of equiprobability. When the proper sub-set is determined, this is again subdivided into equiprobability subsets. If this process can be continued the number of trials expected when each division is into two subsets will be 
H(K)h = 
log 2 
   If each test has Spossible results and each of these corresponds to the key being in one of Sequiprobability subsets, then 
H(K)h = 
log S 
trials will be expected. The intuitive signi?cance of these results should be noted. In the two-compartment test with equiprobability, each test yields one bit of information as to the key. If the subsets have very different probabilities, is in testing a single key in complete trial and error, only a small amount of information is obtained from the test. Thus with 26equiprobable keys, a test of one yields only 
26! ? 1 26! ? 11 1 
? log + log
26! 26! 26! 26! 
or about 10?25bits of information. Dividing into Sequiprobability subsets maximizes the information obtained from each trial at logS, and the ex-pected number of trials is the total information to be obtained, that is H(K)divided by this amount. 
   The question here is similar to various coin weighing problems that have been circulated recently. A typical example is the following: It is known that one coin in 27is counterfeit, and slightly lighter than the rest. A chemist’s balance is available and the counterfeit coin is to be isolated by a series of weighings. What the least number of weighings required to do this? The cor-rect answer is 3, obtained by ?rst dividing the coins into three groups of 9each. Two of these are compared on the balance. The three possible results determine the set of 9containing the counterfeit. This set is then divided into 3subsets of 3each and the process continued. The set of coins corresponds to the set of keys, the counterfeit coin to the correct key, and the weighing procedure to a trial or test. The original uncertainty is log227 bits, and each trial yields log23 bits of information; thus, when there is no “diophantine trouble”, log 2 27 or 3 trials are suf?cient. 
log 2 3 
   This method of solution is feasible only if the key space can be divided into a small number of subsets, with a simple method of determining the subset to which the correct key belongs. One does not need to assume a com-plete key in order to apply a consistency test and determine if the assumption is justi?ed—an assumption on a part of the key (or as to whether the key is in some large section of the key space) can be tested. In other words it is possible to solve for the key bit by bit. 
   The possibility of this method of analysis is the crucial weakness of most ciphering systems. For example, in simple substitution, an assumption on a single letter can be checked against its frequency, variety of contact, doubles or reversals, etc. In determining a single letter the key space is reduced by 1.4decimal digits from the original 26. The same effect is seen in all the elemen-tary types of ciphers. In the Vigen`ere, the assumption of two or three letters of the key is easily checked by deciphering at other points with this fragment and nothing whether clear emerges. The compound Vigen`ere is much better from this point of view, if we assume a fairly large number of component pe-riods, producing a repetition rate larger than will be intercepted. In this case as many key letters are used in enciphering each letter as there are periods. Although this is only a fraction of the entire key, at least a fair number of letters must be assumed before a consistency check can be applied. 
   Our ?rst conclusion then, regarding practical small key cipher design, is that a considerable amount of key should be used in enciphering each small element of the message. 
23 STATISTICAL METHODS 
It is possible to solve many kinds of ciphers by statistical analysis. Consider again simple substitution. The ?rst thing a cryptanalyst does with an inter-cepted cryptogram is to make a frequency count. If the cryptogram contains, say, 200 letters it is safe to assume that few, if any, of the letters are out of their frequency groups, this being a division into 4 sets of well de?ned fre-quency limits. The logarithm of the number of keys within this limitation may be calculated as 
log2!9!9!6!=14.28
and the simple frequency count thus reduces the key uncertainty by 12 deci-mal digits, a tremendous gain. 
   In general, a statistical attack proceeds as follows: A certain statistic is measured on the intercepted cryptogram E. This statistic is such that for all reasonable message  M it assumes about the same value, SK, the value de-pending only on the particular key Kthat was used. The value thus obtained serves to limit the possible keys to those which would give values of Sin the neighborhood of that observed. A statistic which does not depend on Kor which varies as much with Mas with Kis not of value in limiting K. Thus, in transposition ciphers, the frequency count of letters gives no information about K—every Kleaves this statistic the same. Hence one can make no use of a frequency count in breaking transposition ciphers. 
   More precisely one can ascribe a “solving power” to a given statistic S. For each value if Sthere will be a conditional equivocation of the key HS(K), the equivocation when Shas its particular value, and that is all that is known concerning the key. The weighted mean of these values 
P(S)HS(K)
gives the mean equivocation of the key when Sis known, P(S)being the a priori probability of the particular value S. The key size H(K), less this mean equivocation, measures the “solving power” of the statistic S. 
   In a strongly ideal cipher all statistics of the cryptogram are independent of the particular key used. This is the measure preserving property of TjTk ?1 on the Espace or Tj ?1Tkon the Mspace mentioned above. 
   There are good and poor statistics, just as there are good and poor meth-ods of trial and error. Indeed the trial and error testing of an hypothesis is a type of statistic, and what was said above regarding the best types of trials holds generally. A good statistic for solving a system must have the following properties: 
1 It must be simple to measure. 
2 It must depend more on the key than on the message if it is meant to solve for the key. The variation with Mshould not mask its variation with K. 
3 The values of the statistic that can be “resolved” in spite of the “fuzziness” produced by variation in Mshould divide the key space into a number of subsets of comparable probability, with the statistic specifying the one in which the correct key lies. The statistic should give us sizeable informa-tion about the key, not a tiny fraction of a bit. 
4 The information it gives must be simple and usable. Thus the subsets in which the statistic locates the key must be of a simple nature in the key space. 

   Frequency count for simple substitution is an example of a very good statistic. 
   Two methods (other than recourse to ideal systems) suggest themselves for frustrating a statistical analysis. These we may call the methods of diffu-sion and confusion. In the method of diffusion the statistical structure of Mwhich leads to its redundancy is “dissipated” into long range statistics—i.e., 
into statistical structure involving long combinations of letters in the cryp-togram. The effect here is that the enemy must intercept a tremendous amount of material to tie down this structure, since the structure is evident only in blocks of very small individual probability. Furthermore, even when he has suf?cient material, the analytical work required is much greater since the redundancy has been diffused over a large number of individual statis-tics. An example of diffusion of statistics is operating on a message M=m1,m2,m3,···with an “averaging” operation, e.g., 
     s yn = ? mn+i(mod 26),i=1
adding s successive letters of the message to get a letter yn. One can show that the redundancy of the ysequence is the same as that of the msequence, but the structure has been dissipated. Thus the letter frequencies in ywill be more nearly equal than in m, the digram frequencies also more nearly equal, etc. Indeed any reversible operation which produces one letter out for each letter in and does not have an in?nite “memory” has an output with the same redundancy as the input. The statistics can never be eliminated without compression, but they can be spread out. 
   The method of confusion is to make the relation between the simple statis-tics of Eand the simple description of Ka very complex and involved one. In the case of simple substitution, it is easy to describe the limitation of Kimposed by the letter frequencies of E. If the connection is very involved and confused the enemy may still be able to evaluate a statistic S1, say, which limits the key to a region of the key space. This limitation, however, is to some complex region Rin the space, perhaps “folded ever” many times, and he has a dif?cult time making use of it. A second statistic S2limits Kstill further to R2, hence it lies in the intersection region; but this does not help much because it is so dif?cult to determine just what the intersection is. 
   To be more precise let us suppose the key space has certain “natural co-ordinates” k1,k2,···,kpwhich he wishes to determine. He measures, let us say, a set of statistics s1,s2,···,snand these are suf?cient to determine the ki. However, in the method of confusion, the equations connecting these sets of variable are involved and complex. We have, say, 
f1(k1,k2,···,kp)=s1f2(k1,k2,···,kp)=s2...
fn(k1,k2,···,kp)=sn,
709 
and all the fiinvolve all the ki. The cryptographer must solve this system simultaneously—a dif?cult job. In the simple (not confused) cases the func-tions involve only a small number of the ki—or at least some of these do. One ?rst solves the simpler equations, evaluating some of the ki and substitutes these in the more complicated equations. 
   The confusion here is that for a good ciphering system steps should be taken either to diffuse or confuse the redundancy (or both). 
24 THE PROBABLE WORLD METHOD 
One of the most powerful tools for breaking ciphers is the use of probable words. The probable words may be words or phrases expected in the par-ticular message due to its source, or they may merely be common words or syllables which occur in any text in the language, such as the, and, tion, that, and the like in English. 
   In general, the probable word method is used as follows: Assuming a probable word to be at some point in the clear, the key or a part of the key is determined. This is used to decipher other parts of the cryptogram and pro-vide a consistency test. If the other parts come out in the clear, the assumption is justi?ed. 
   There are few of the classical type ciphers that use a small key and can re-sist long under a probable word analysis. From a consideration of this method we can frame a test of ciphers which might be called the acid test. It applies only to ciphers with a small key (less than, say, 50 decimal digits), applied to natural languages, and not using the ideal method of gaining secrecy. The acid test is this: How dif?cult is it to determine the key or a part of the key knowing a small sample of message and corresponding cryptogram? Any system in which this is easy cannot be very resistant, for the cryptanalyst can always make use of probable words, combined with trial and error, until a consistent solution is obtained. 
   The conditions on the size of the key make the amount of trial and error small, and the condition about ideal systems is necessary, since these au-tomatically give consistency checks. The existence of probable words and phrases is implied by the assumption of natural languages. 
   Note that the requirement of dif?cult solution under these conditions is not, by itself, contradictory to the requirements that enciphering and deci-phering be simple processes. Using functional notation we have for enci-phering 
E=f(K,M)
and for deciphering 
M=g(K,E)
710 
Both of these may be simple operations on their arguments without the third equation 
K=h(M,E)
being simple. 
   We may also point out that in investigating a new type of ciphering sys-tem one of the best methods of attack is to consider how the key could be determined if a suf?cient amount of Mand Ewere given. 
   The principle of confusion can be (and must be) used to create dif?culties for the cryptanalyst using probable word techniques. Given (or assuming) M=m1,m2,···,msand E=e1,e2,···,es, the cryptanalyst can set up equations for the different key elements k1,k2,···,kr(namely the encipher-ing equations). 
e1=f1(m1,m2,···,ms;k1,···,kr)e1=f2(m1,m2,···,ms;k1,···,kr)
. . . . 
e1=fs(m1,m2,···,ms;k1,···,kr)
All is known, we assume, except the ki. Each of these equations should there-fore be complex in the ki, and involve many of them. Otherwise the enemy can solve the simple ones and then the more complex ones by substitution. 
   From the point of view of increasing confusion, it is desirable to have the fiinvolve several mi, especially if these are not adjacent and hence less correlated. This introduces the undesirable feature of error propagation, how-ever, for then each eiwill generally affect several miin deciphering, and an error will spread to all these. 
   We conclude that much of the key should be used in an involved manner in obtaining any cryptogram letter from the message to keep the work characteristic high. Further a dependence on several uncorrelated mi is desirable, if some propagation of error can be tolerated. We are led by all three of the arguments of these sections to consider “mixing transformations”. 
25 MIXING TRANSFORMATIONS 
A notion that has proved valuable in certain branches of probability theory is the concept of a mixing transformation. Suppose we have a probability or measure space ?and a measure preserving transformation Fof the space into itself, that is, a transformation such that the measure of a transformed region FRis equal to the measure of the initial region R. The transformation is called mixing if for any function de?ned over the space and any region Rthe integral of the function over the region RnRapproaches, as n??, the integral of the function over the entire space ?multiplied by the volume of R. This means that any initial region Ris mixed with uniform density throughout the entire space if Fis applied a large number of times. In general, FnRbecomes a region consisting of a large number of thin ?laments spread throughout ?. As nincreases the ?laments become ?ner and their density more constant. 
   A mixing transformation in this precise sense can occur only in a space with an in?nite number of points, for in a ?nite point space the transforma-tion must be periodic. Speaking loosely, however, we can think of a mixing transformation as one which distributes any reasonably cohesive region in the space fairly uniformly over the entire space. If the ?rst region could be described in simple terms, the second would require very complex ones. 
   In cryptography we can think of all the possible messages of length Nas the space ?and the high probability messages as the region R. This latter group has a certain fairly simple statistical structure. If a mixing transforma-tion were applied, the high probability messages would be scattered evenly throughout the space. 
   Good mixing transformations are often formed by repeated products of two simple non-commuting operations. Hopf13 has shown, for example, that pastry dough can be mixed by such a sequence of operations. The dough is ?rst rolled out into a thin slab, then folded over, then rolled, and the folded again, etc. 
   In a good mixing transformation of a space with natural coordinates X1,X2,···,XSthe point Xiis carried by the transformation into a point Xi? , with 
Xi ? =f1(X1,X2,···,XS)i=1,2,···,S
and the functions fiare complicated, involving all the variables in a “sensi-tive” way. A small variation of any one, X3, say, changes all the Xi ? considerably. If Xipasses through its range of possible variation the point Xi ? traces a long winding path around the space. 
   Various methods of mixing applicable to statistical sequences of the type found in natural languages can be devised. One which looks fairly good is to follow a preliminary transposition by a sequence of alternating substitutions and simple linear operations, adding adjacent letters mod 26 for example. Thus we might take 
13 E. Hopf, “On Causality, Statistics and Probability,” Journal of Math. and Physics, v. 13, pp. 51-102, 1934. 
F = LSLSLT

where Tis a transposition, Lis a linear operation, and Sis a substitution. 
26 CIPHERS OF THE TYPE TkFSj 
Suppose that Fis a good mixing transformation that can be applied to se-quences of letters, and that Tkand Sjare any two simple families of transfor-mations, i.e., two simple ciphers, which may be the same. For concreteness we may think of them as both simple substitutions. 
   It appears that the cipher TFSwill be a very good secrecy system from the standpoint of its work characteristic. In the ?rst place it is clear on review-ing our arguments about statistical methods that no simple statistics will give information about the key—any signi?cant statistic derived from Emust be of a highly involved and very sensitive type—the redundancy has been both diffused and confused by the mixing transformation F. Also probable words lead to a complex system of equations involving all parts of the key (when the mix is good), which must be solved simultaneously. 
   It is interesting to note that if the cipher Tis omitted the remaining sys-tem is similar to Sand thus no stronger. The enemy merely “unmixes” the cryptogram by application of F?1 and then solves. If Sis omitted the remain-ing system is much stronger than Talone when the mix is good, but still not comparable to TFS. 
   The basic principle here of simple ciphers separated by a mixing trans-formation can of course be extended. For example one could use 
TkF1SjF2Ri
with two mixes and three simple ciphers. One can also simplify by using the same ciphers, and even the same keys as well as the same mixing transfor-mations. This might well simplify the mechanization of such systems. 
   The mixing transformation which separates the two (or more) appear-ances of the key acts as a kind of barrier for the enemy—it is easy to carry a known element over this barrier but an unknown (the key) does not go easily. 
   By supplying two sets of unknowns, the key for Sand the key for T, and separating them by the mixing transformation Fwe have “entangled” the unknowns together in a way that makes solution very dif?cult. 
   Although systems constructed on this principle would be extremely safe they possess one grave disadvantage. If the mix is good then the propagation of errors is bad. A transmission error of one letter will affect several letters on deciphering. 
27INCOMPATIBILITY OF THE CRITERIA FOR GOOD SYSTEMS 
The ?ve criteria for good secrecy systems given in section 5 appear to have a certain incompatibility when applied to a natural language with its compli-cated statistical structure. With arti?cial languages having a simple statistical structure it is possible to satisfy all requirements simultaneously, by means of the ideal type ciphers. In natural languages a compromise must be made and the valuations balanced against one another with a view toward the particular application. 
   If any one of the ?ve criteria is dropped, the other four can be satis?ed fairly well, as the following example show: 
1 If we omit the ?rst requirement (amount of secrecy) any simple cipher such as simple substitution will do. In the extreme case of omitting this condition completely, no cipher at all is required and one sends the clear! 
2 If the size of the key is not limited the Vernam system can be used. 
3 If complexity of operation is not limited, various extremely complicated types of enciphering process can be used. 
4 If we omit the propagation of error condition, systems of the type TFSwould be very good, although somewhat complicated. 
5 If we allow large expansion of message, various systems are easily de-vised where the “correct” message is mixed with many “incorrect” ones (misinformation). The key determines which of these is correct. 

   A very rough argument for the incompatibility of the ?ve conditions may be given as follows: From condition 5, secrecy system essentially as studied in this paper must be used; i.e., no great use of nulls, etc. Perfect and ideal systems are excluded by condition 2 and by 3 and 4, respectively. The high secrecy required by 1 must then come from a high work characteristic, not from a high equivocation characteristic. If key is small, the system simple, and the errors do not propagate, probable word methods will generally solve the system fairly easily since we then have a fairly simple system of equations for the key. 
   This reasoning is too vague to be conclusive, but the general idea seems quite reasonable. Perhaps if the various criteria could be given quantitative signi?cance, some sort of an exchange equation could be found involving them and giving the best physically compatible sets of values. The two most dif?cult to measure numerically are the complexity of operations, and the complexity of statistical structure of the language. 
APPENDIX 
Proof of Theorem 3 
   Select any message M1and group together all cryptograms that can be obtained from M1by any enciphering operation Ti. Let this class of crypto-grams be C1? . Group with M1all messages that can be obtained from M1by Ti ?1TjM1, and call this class C1. The same C1 ? would be obtained if we started with any other  M in  C1 since 
TsTj ?1TiM1=TlM1.
Similarly the same C1 would be obtained. 
   Choosing an M not in C1(if any such exist) we construct C2and C2 ? in the same way. Continuing in this manner we obtain the residue classes with properties (1) and (2). Let M1and M2be in C1and suppose 
M2=T1T2 ?1M1.
If E1is in C1 ? and can be obtained from M1by 
E1=T?M1=T?M1=···=T?M1,
then 
E1=T?T2 ?1T1M2=T?T2 ?1T1M2=···=T?M2=TµM2···
Thus each Miin C1transforms into E1by the same number of keys. Similarly each Eiin C1 ? is obtained from any Min C1by the same number of keys. It follows that this number of keys is a divisor of the total number of keys and hence we have properties (3) and (4). 
PostScript by Jiejun Kong: 
    Many papers die before their authors die. Nevertheless, some papers will be read and referred until they become part of our life. In that context they live forever. 
    Claude Elwood Shannon died Saturday, February 24, 2001 at the Courtyard Nursing Care Center in Medford, Massachusetts. He was 84 years old. Though he has left the world, I believe this classical paper “Communication Theory of Secrecy Systems” will not. 
    I am working at network security area and Shannon’s work always amazes me. Recently I am shocked to ?nd that this paper does not have a typesetted version on the colossal Internet, the only thing people can get is a set of barely-legible scanned JPEG images from photocopies (see http: //www3.edgenet.net/dcowley/docs.html). So here is my memorial service to the great man. I spent a lot of time to input and inspect the entire contents of this 60-page paper. During my typesetting I am convinced that his genius is worth the time and effort I spent! 
    Although not every word looks exactly like the original copy, I can assure the correctness of contents, page numbers, places of theorems, ?gures, and footnotes, etc., as you have read from your printout. 
    Salute to Dr. Shannon and thank you for reading this postscript. 
